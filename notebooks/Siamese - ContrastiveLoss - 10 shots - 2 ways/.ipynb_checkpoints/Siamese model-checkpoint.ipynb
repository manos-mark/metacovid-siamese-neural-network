{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9bc068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0927a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.1.0\n",
      "\t• tf.keras version: 2.2.4-tf\n",
      "\t• Running on GPU\n"
     ]
    }
   ],
   "source": [
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f60667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 3 classes.\n",
      "The train set contains 30\n",
      "Found 30 images belonging to 3 classes.\n",
      "The valid set contains 30\n",
      "Found 648 images belonging to 3 classes.\n",
      "The test set contains 648\n"
     ]
    }
   ],
   "source": [
    "basedir = os.path.join(\"C:\\\\Users\\\\aktas\\\\Desktop\\\\VIBOT\\\\3.semester\\\\Meta-Learning\\\\project_final\\\\metacovid-siamese-neural-network\", \"dataset\", \"siamese\") \n",
    "\n",
    "train_image_list, train_y_list = utils.load_images(basedir, 'train', (100,100))\n",
    "print(\"The train set contains\",len(train_image_list)) \n",
    "\n",
    "valid_image_list, valid_y_list = utils.load_images(basedir, 'validation', (100,100))   \n",
    "print(\"The valid set contains\", len(valid_image_list))  \n",
    "\n",
    "test_image_list, test_y_list = utils.load_images(basedir, 'test', (100,100))   \n",
    "print(\"The test set contains\", len(test_image_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a873fba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs for training 60\n",
      "number of pairs for validation 60\n",
      "number of pairs for test 1296\n"
     ]
    }
   ],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train = utils.make_pairs(train_image_list, train_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_val, labels_val = utils.make_pairs(valid_image_list, valid_y_list)\n",
    "\n",
    "# make test pairs\n",
    "pairs_test, labels_test = utils.make_pairs(test_image_list, test_y_list)\n",
    "\n",
    "x_train_1 = pairs_train[:, 0]  \n",
    "x_train_2 = pairs_train[:, 1]\n",
    "print(\"number of pairs for training\", np.shape(x_train_1)[0]) \n",
    "\n",
    "x_val_1 = pairs_val[:, 0] \n",
    "x_val_2 = pairs_val[:, 1]\n",
    "print(\"number of pairs for validation\", np.shape(x_val_1)[0]) \n",
    "\n",
    "x_test_1 = pairs_test[:, 0] \n",
    "x_test_2 = pairs_test[:, 1]\n",
    "print(\"number of pairs for test\", np.shape(x_test_1)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9dade0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 5120)         14748995    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "SIAMESE_MODEL_FNAME = 'siamese_network.h5'\n",
    "EMBEDDING_MODEL_FNAME = 'embedding_network2w.h5'\n",
    "\n",
    "input_1 = Input((100,100,3))\n",
    "input_2 = Input((100,100,3))\n",
    "\n",
    "embedding_network = tf.keras.models.load_model(EMBEDDING_MODEL_FNAME)\n",
    "embedding_network.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential() \n",
    "for layer in embedding_network.layers:  \n",
    "    model.add(layer) \n",
    "\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dense(5120, name='den', activation='sigmoid', kernel_regularizer='l2')) \n",
    " \n",
    "output_1 = model(input_1) \n",
    "output_2 = model(input_2) \n",
    " \n",
    "merge_layer = Lambda(utils.manhattan_distance)([output_1, output_2]) \n",
    "output_layer = Dense(1, activation=\"sigmoid\")(merge_layer) \n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer) \n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b4a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" callbacks \"\"\"\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.0001)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='siamese_network.h5', verbose=1, \n",
    "                                save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b21af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 5120)         14748995    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60 samples, validate on 60 samples\n",
      "Epoch 1/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.2280 - accuracy: 0.5741\n",
      "Epoch 00001: val_loss improved from inf to 0.31372, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 4s 66ms/sample - loss: 0.2181 - accuracy: 0.6000 - val_loss: 0.3137 - val_accuracy: 0.5500\n",
      "Epoch 2/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1994 - accuracy: 0.5926\n",
      "Epoch 00002: val_loss improved from 0.31372 to 0.28498, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1955 - accuracy: 0.6167 - val_loss: 0.2850 - val_accuracy: 0.5500\n",
      "Epoch 3/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1824 - accuracy: 0.6379\n",
      "Epoch 00003: val_loss improved from 0.28498 to 0.25892, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1770 - accuracy: 0.6500 - val_loss: 0.2589 - val_accuracy: 0.5667\n",
      "Epoch 4/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.6610\n",
      "Epoch 00004: val_loss improved from 0.25892 to 0.23773, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 22ms/sample - loss: 0.1623 - accuracy: 0.6667 - val_loss: 0.2377 - val_accuracy: 0.5667\n",
      "Epoch 5/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1475 - accuracy: 0.7500\n",
      "Epoch 00005: val_loss improved from 0.23773 to 0.21738, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 23ms/sample - loss: 0.1507 - accuracy: 0.7500 - val_loss: 0.2174 - val_accuracy: 0.5667\n",
      "Epoch 6/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1370 - accuracy: 0.8036\n",
      "Epoch 00006: val_loss improved from 0.21738 to 0.19809, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 22ms/sample - loss: 0.1417 - accuracy: 0.8000 - val_loss: 0.1981 - val_accuracy: 0.5833\n",
      "Epoch 7/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1396 - accuracy: 0.8519\n",
      "Epoch 00007: val_loss improved from 0.19809 to 0.18039, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1349 - accuracy: 0.8500 - val_loss: 0.1804 - val_accuracy: 0.6667\n",
      "Epoch 8/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1293 - accuracy: 0.8814\n",
      "Epoch 00008: val_loss improved from 0.18039 to 0.16893, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1312 - accuracy: 0.8833 - val_loss: 0.1689 - val_accuracy: 0.7000\n",
      "Epoch 9/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1367 - accuracy: 0.9091\n",
      "Epoch 00009: val_loss did not improve from 0.16893\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1296 - accuracy: 0.9167 - val_loss: 0.1727 - val_accuracy: 0.7000\n",
      "Epoch 10/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1332 - accuracy: 0.9259\n",
      "Epoch 00010: val_loss did not improve from 0.16893\n",
      "60/60 [==============================] - 1s 19ms/sample - loss: 0.1288 - accuracy: 0.9167 - val_loss: 0.1715 - val_accuracy: 0.7000\n",
      "Epoch 11/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 0.9138\n",
      "Epoch 00011: val_loss improved from 0.16893 to 0.16165, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1276 - accuracy: 0.9167 - val_loss: 0.1616 - val_accuracy: 0.7167\n",
      "Epoch 12/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1289 - accuracy: 0.9123\n",
      "Epoch 00012: val_loss improved from 0.16165 to 0.16120, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1265 - accuracy: 0.9167 - val_loss: 0.1612 - val_accuracy: 0.7167\n",
      "Epoch 13/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1280 - accuracy: 0.9153\n",
      "Epoch 00013: val_loss did not improve from 0.16120\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1259 - accuracy: 0.9167 - val_loss: 0.1715 - val_accuracy: 0.7167\n",
      "Epoch 14/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1252 - accuracy: 0.9259\n",
      "Epoch 00014: val_loss did not improve from 0.16120\n",
      "60/60 [==============================] - 1s 19ms/sample - loss: 0.1255 - accuracy: 0.9167 - val_loss: 0.1680 - val_accuracy: 0.7167\n",
      "Epoch 15/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1186 - accuracy: 0.9091\n",
      "Epoch 00015: val_loss did not improve from 0.16120\n",
      "60/60 [==============================] - 1s 19ms/sample - loss: 0.1245 - accuracy: 0.9167 - val_loss: 0.1634 - val_accuracy: 0.7167\n",
      "Epoch 16/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1256 - accuracy: 0.9273\n",
      "Epoch 00016: val_loss improved from 0.16120 to 0.16098, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1237 - accuracy: 0.9167 - val_loss: 0.1610 - val_accuracy: 0.7167\n",
      "Epoch 17/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1249 - accuracy: 0.9273\n",
      "Epoch 00017: val_loss improved from 0.16098 to 0.15977, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1231 - accuracy: 0.9167 - val_loss: 0.1598 - val_accuracy: 0.7167\n",
      "Epoch 18/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1231 - accuracy: 0.9074\n",
      "Epoch 00018: val_loss did not improve from 0.15977\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1226 - accuracy: 0.9167 - val_loss: 0.1629 - val_accuracy: 0.7167\n",
      "Epoch 19/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9153\n",
      "Epoch 00019: val_loss improved from 0.15977 to 0.15844, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1222 - accuracy: 0.9167 - val_loss: 0.1584 - val_accuracy: 0.7333\n",
      "Epoch 20/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 0.9310\n",
      "Epoch 00020: val_loss did not improve from 0.15844\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1215 - accuracy: 0.9167 - val_loss: 0.1595 - val_accuracy: 0.7167\n",
      "Epoch 21/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1204 - accuracy: 0.9286\n",
      "Epoch 00021: val_loss did not improve from 0.15844\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1208 - accuracy: 0.9167 - val_loss: 0.1614 - val_accuracy: 0.7167\n",
      "Epoch 22/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.9310\n",
      "Epoch 00022: val_loss did not improve from 0.15844\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1206 - accuracy: 0.9167 - val_loss: 0.1658 - val_accuracy: 0.7167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1222 - accuracy: 0.9153\n",
      "Epoch 00023: val_loss improved from 0.15844 to 0.15662, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1201 - accuracy: 0.9167 - val_loss: 0.1566 - val_accuracy: 0.7333\n",
      "Epoch 24/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1150 - accuracy: 0.9286\n",
      "Epoch 00024: val_loss did not improve from 0.15662\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1193 - accuracy: 0.9167 - val_loss: 0.1589 - val_accuracy: 0.7500\n",
      "Epoch 25/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9153\n",
      "Epoch 00025: val_loss improved from 0.15662 to 0.15613, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1188 - accuracy: 0.9167 - val_loss: 0.1561 - val_accuracy: 0.7500\n",
      "Epoch 26/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1147 - accuracy: 0.9074\n",
      "Epoch 00026: val_loss improved from 0.15613 to 0.15344, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1183 - accuracy: 0.9167 - val_loss: 0.1534 - val_accuracy: 0.7833\n",
      "Epoch 27/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1180 - accuracy: 0.9074\n",
      "Epoch 00027: val_loss did not improve from 0.15344\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1176 - accuracy: 0.9167 - val_loss: 0.1596 - val_accuracy: 0.7500\n",
      "Epoch 28/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1194 - accuracy: 0.9123\n",
      "Epoch 00028: val_loss did not improve from 0.15344\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1172 - accuracy: 0.9167 - val_loss: 0.1552 - val_accuracy: 0.7833\n",
      "Epoch 29/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1148 - accuracy: 0.9464\n",
      "Epoch 00029: val_loss did not improve from 0.15344\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1167 - accuracy: 0.9167 - val_loss: 0.1554 - val_accuracy: 0.7833\n",
      "Epoch 30/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1208 - accuracy: 0.9074\n",
      "Epoch 00030: val_loss did not improve from 0.15344\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1164 - accuracy: 0.9167 - val_loss: 0.1555 - val_accuracy: 0.7833\n",
      "Epoch 31/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1182 - accuracy: 0.9123\n",
      "Epoch 00031: val_loss did not improve from 0.15344\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1160 - accuracy: 0.9167 - val_loss: 0.1551 - val_accuracy: 0.7833\n",
      "Epoch 32/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1109 - accuracy: 0.9259\n",
      "Epoch 00032: val_loss did not improve from 0.15344\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1151 - accuracy: 0.9333 - val_loss: 0.1545 - val_accuracy: 0.7833\n",
      "Epoch 33/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1171 - accuracy: 0.9298\n",
      "Epoch 00033: val_loss did not improve from 0.15344\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1150 - accuracy: 0.9333 - val_loss: 0.1536 - val_accuracy: 0.8000\n",
      "Epoch 34/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1072 - accuracy: 0.9259\n",
      "Epoch 00034: val_loss improved from 0.15344 to 0.15314, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1149 - accuracy: 0.9333 - val_loss: 0.1531 - val_accuracy: 0.8000\n",
      "Epoch 35/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1187 - accuracy: 0.9310\n",
      "Epoch 00035: val_loss did not improve from 0.15314\n",
      "60/60 [==============================] - 1s 19ms/sample - loss: 0.1148 - accuracy: 0.9333 - val_loss: 0.1532 - val_accuracy: 0.8000\n",
      "Epoch 36/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9322\n",
      "Epoch 00036: val_loss improved from 0.15314 to 0.15310, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1147 - accuracy: 0.9333 - val_loss: 0.1531 - val_accuracy: 0.8000\n",
      "Epoch 37/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9322\n",
      "Epoch 00037: val_loss improved from 0.15310 to 0.15306, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1146 - accuracy: 0.9333 - val_loss: 0.1531 - val_accuracy: 0.8000\n",
      "Epoch 38/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.9298\n",
      "Epoch 00038: val_loss did not improve from 0.15306\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1145 - accuracy: 0.9333 - val_loss: 0.1536 - val_accuracy: 0.8000\n",
      "Epoch 39/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1107 - accuracy: 0.9649\n",
      "Epoch 00039: val_loss did not improve from 0.15306\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1145 - accuracy: 0.9333 - val_loss: 0.1538 - val_accuracy: 0.8000\n",
      "Epoch 40/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1146 - accuracy: 0.9286\n",
      "Epoch 00040: val_loss improved from 0.15306 to 0.15244, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 22ms/sample - loss: 0.1143 - accuracy: 0.9333 - val_loss: 0.1524 - val_accuracy: 0.8000\n",
      "Epoch 41/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1164 - accuracy: 0.9298\n",
      "Epoch 00041: val_loss did not improve from 0.15244\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1142 - accuracy: 0.9333 - val_loss: 0.1525 - val_accuracy: 0.8000\n",
      "Epoch 42/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1165 - accuracy: 0.9273\n",
      "Epoch 00042: val_loss improved from 0.15244 to 0.15216, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1142 - accuracy: 0.9333 - val_loss: 0.1522 - val_accuracy: 0.8000\n",
      "Epoch 43/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1110 - accuracy: 0.9455\n",
      "Epoch 00043: val_loss did not improve from 0.15216\n",
      "60/60 [==============================] - 1s 19ms/sample - loss: 0.1142 - accuracy: 0.9333 - val_loss: 0.1531 - val_accuracy: 0.8000\n",
      "Epoch 44/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1225 - accuracy: 0.9259\n",
      "Epoch 00044: val_loss did not improve from 0.15216\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1141 - accuracy: 0.9333 - val_loss: 0.1523 - val_accuracy: 0.8000\n",
      "Epoch 45/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1105 - accuracy: 0.9310\n",
      "Epoch 00045: val_loss did not improve from 0.15216\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1141 - accuracy: 0.9333 - val_loss: 0.1525 - val_accuracy: 0.8000\n",
      "Epoch 46/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1159 - accuracy: 0.9322\n",
      "Epoch 00046: val_loss did not improve from 0.15216\n",
      "60/60 [==============================] - 1s 19ms/sample - loss: 0.1140 - accuracy: 0.9333 - val_loss: 0.1523 - val_accuracy: 0.8000\n",
      "Epoch 47/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1122 - accuracy: 0.9298\n",
      "Epoch 00047: val_loss did not improve from 0.15216\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1140 - accuracy: 0.9333 - val_loss: 0.1524 - val_accuracy: 0.8000\n",
      "Epoch 48/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1123 - accuracy: 0.9474\n",
      "Epoch 00048: val_loss did not improve from 0.15216\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1139 - accuracy: 0.9500 - val_loss: 0.1524 - val_accuracy: 0.8000\n",
      "Epoch 49/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1097 - accuracy: 0.9483\n",
      "Epoch 00049: val_loss did not improve from 0.15216\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1139 - accuracy: 0.9333 - val_loss: 0.1525 - val_accuracy: 0.8000\n",
      "Epoch 50/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9322\n",
      "Epoch 00050: val_loss improved from 0.15216 to 0.15194, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1138 - accuracy: 0.9333 - val_loss: 0.1519 - val_accuracy: 0.8000\n",
      "Epoch 51/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9492\n",
      "Epoch 00051: val_loss did not improve from 0.15194\n",
      "60/60 [==============================] - 1s 19ms/sample - loss: 0.1138 - accuracy: 0.9500 - val_loss: 0.1520 - val_accuracy: 0.8000\n",
      "Epoch 52/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1115 - accuracy: 0.9474\n",
      "Epoch 00052: val_loss did not improve from 0.15194\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1137 - accuracy: 0.9500 - val_loss: 0.1521 - val_accuracy: 0.8000\n",
      "Epoch 53/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1196 - accuracy: 0.9474\n",
      "Epoch 00053: val_loss did not improve from 0.15194\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1137 - accuracy: 0.9500 - val_loss: 0.1520 - val_accuracy: 0.8000\n",
      "Epoch 54/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1215 - accuracy: 0.9630\n",
      "Epoch 00054: val_loss improved from 0.15194 to 0.15191, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1136 - accuracy: 0.9667 - val_loss: 0.1519 - val_accuracy: 0.8000\n",
      "Epoch 55/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9655\n",
      "Epoch 00055: val_loss did not improve from 0.15191\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1136 - accuracy: 0.9667 - val_loss: 0.1520 - val_accuracy: 0.8000\n",
      "Epoch 56/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9492\n",
      "Epoch 00056: val_loss improved from 0.15191 to 0.15160, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1135 - accuracy: 0.9500 - val_loss: 0.1516 - val_accuracy: 0.8000\n",
      "Epoch 57/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9483\n",
      "Epoch 00057: val_loss did not improve from 0.15160\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1135 - accuracy: 0.9500 - val_loss: 0.1516 - val_accuracy: 0.8000\n",
      "Epoch 58/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1173 - accuracy: 0.9655\n",
      "Epoch 00058: val_loss did not improve from 0.15160\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1134 - accuracy: 0.9667 - val_loss: 0.1517 - val_accuracy: 0.8000\n",
      "Epoch 59/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1132 - accuracy: 0.9444\n",
      "Epoch 00059: val_loss did not improve from 0.15160\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1134 - accuracy: 0.9500 - val_loss: 0.1516 - val_accuracy: 0.8000\n",
      "Epoch 60/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9483\n",
      "Epoch 00060: val_loss did not improve from 0.15160\n",
      "60/60 [==============================] - 1s 19ms/sample - loss: 0.1134 - accuracy: 0.9500 - val_loss: 0.1517 - val_accuracy: 0.8000\n",
      "Epoch 61/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 0.9661\n",
      "Epoch 00061: val_loss did not improve from 0.15160\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1133 - accuracy: 0.9667 - val_loss: 0.1521 - val_accuracy: 0.8000\n",
      "Epoch 62/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 0.9655\n",
      "Epoch 00062: val_loss improved from 0.15160 to 0.15129, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1132 - accuracy: 0.9667 - val_loss: 0.1513 - val_accuracy: 0.8000\n",
      "Epoch 63/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1096 - accuracy: 0.9630\n",
      "Epoch 00063: val_loss did not improve from 0.15129\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1132 - accuracy: 0.9667 - val_loss: 0.1515 - val_accuracy: 0.8000\n",
      "Epoch 64/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1152 - accuracy: 0.9649\n",
      "Epoch 00064: val_loss did not improve from 0.15129\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1131 - accuracy: 0.9667 - val_loss: 0.1515 - val_accuracy: 0.8000\n",
      "Epoch 65/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1190 - accuracy: 0.9474\n",
      "Epoch 00065: val_loss did not improve from 0.15129\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1131 - accuracy: 0.9500 - val_loss: 0.1513 - val_accuracy: 0.8000\n",
      "Epoch 66/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1131 - accuracy: 0.9655\n",
      "Epoch 00066: val_loss did not improve from 0.15129\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1130 - accuracy: 0.9667 - val_loss: 0.1514 - val_accuracy: 0.8000\n",
      "Epoch 67/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 0.9661\n",
      "Epoch 00067: val_loss improved from 0.15129 to 0.15129, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1130 - accuracy: 0.9667 - val_loss: 0.1513 - val_accuracy: 0.8000\n",
      "Epoch 68/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1079 - accuracy: 0.9815\n",
      "Epoch 00068: val_loss did not improve from 0.15129\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1130 - accuracy: 0.9667 - val_loss: 0.1516 - val_accuracy: 0.8000\n",
      "Epoch 69/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9661\n",
      "Epoch 00069: val_loss did not improve from 0.15129\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1129 - accuracy: 0.9667 - val_loss: 0.1514 - val_accuracy: 0.8000\n",
      "Epoch 70/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1147 - accuracy: 0.9661\n",
      "Epoch 00070: val_loss improved from 0.15129 to 0.15083, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1129 - accuracy: 0.9667 - val_loss: 0.1508 - val_accuracy: 0.8000\n",
      "Epoch 71/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9661\n",
      "Epoch 00071: val_loss did not improve from 0.15083\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1128 - accuracy: 0.9667 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 72/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1149 - accuracy: 0.9649\n",
      "Epoch 00072: val_loss did not improve from 0.15083\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1128 - accuracy: 0.9667 - val_loss: 0.1509 - val_accuracy: 0.8000\n",
      "Epoch 73/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.9661\n",
      "Epoch 00073: val_loss did not improve from 0.15083\n",
      "60/60 [==============================] - 1s 19ms/sample - loss: 0.1127 - accuracy: 0.9667 - val_loss: 0.1517 - val_accuracy: 0.8000\n",
      "Epoch 74/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1131 - accuracy: 0.9630\n",
      "Epoch 00074: val_loss improved from 0.15083 to 0.15063, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1127 - accuracy: 0.9667 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 75/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1091 - accuracy: 0.9630\n",
      "Epoch 00075: val_loss did not improve from 0.15063\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1126 - accuracy: 0.9667 - val_loss: 0.1508 - val_accuracy: 0.8000\n",
      "Epoch 76/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1108 - accuracy: 0.9649\n",
      "Epoch 00076: val_loss did not improve from 0.15063\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1126 - accuracy: 0.9667 - val_loss: 0.1511 - val_accuracy: 0.8000\n",
      "Epoch 77/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1097 - accuracy: 0.9636\n",
      "Epoch 00077: val_loss did not improve from 0.15063\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1125 - accuracy: 0.9667 - val_loss: 0.1509 - val_accuracy: 0.8000\n",
      "Epoch 78/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1126 - accuracy: 0.9655\n",
      "Epoch 00078: val_loss improved from 0.15063 to 0.15061, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1125 - accuracy: 0.9667 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 79/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1090 - accuracy: 0.9643\n",
      "Epoch 00079: val_loss did not improve from 0.15061\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1124 - accuracy: 0.9667 - val_loss: 0.1508 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1147 - accuracy: 0.9636\n",
      "Epoch 00080: val_loss did not improve from 0.15061\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1124 - accuracy: 0.9667 - val_loss: 0.1511 - val_accuracy: 0.8000\n",
      "Epoch 81/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1192 - accuracy: 0.9815\n",
      "Epoch 00081: val_loss did not improve from 0.15061\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1123 - accuracy: 0.9667 - val_loss: 0.1514 - val_accuracy: 0.8000\n",
      "Epoch 82/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.9655\n",
      "Epoch 00082: val_loss did not improve from 0.15061\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1123 - accuracy: 0.9667 - val_loss: 0.1507 - val_accuracy: 0.8000\n",
      "Epoch 83/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1142 - accuracy: 0.9649\n",
      "Epoch 00083: val_loss improved from 0.15061 to 0.15034, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1122 - accuracy: 0.9667 - val_loss: 0.1503 - val_accuracy: 0.8000\n",
      "Epoch 84/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.9661\n",
      "Epoch 00084: val_loss did not improve from 0.15034\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1122 - accuracy: 0.9667 - val_loss: 0.1514 - val_accuracy: 0.8000\n",
      "Epoch 85/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1158 - accuracy: 0.9630\n",
      "Epoch 00085: val_loss did not improve from 0.15034\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1121 - accuracy: 0.9667 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 86/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 0.9661\n",
      "Epoch 00086: val_loss did not improve from 0.15034\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1121 - accuracy: 0.9667 - val_loss: 0.1504 - val_accuracy: 0.8000\n",
      "Epoch 87/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1085 - accuracy: 0.9643\n",
      "Epoch 00087: val_loss did not improve from 0.15034\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1120 - accuracy: 0.9667 - val_loss: 0.1505 - val_accuracy: 0.8000\n",
      "Epoch 88/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1158 - accuracy: 0.9655\n",
      "Epoch 00088: val_loss improved from 0.15034 to 0.15024, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1120 - accuracy: 0.9667 - val_loss: 0.1502 - val_accuracy: 0.8000\n",
      "Epoch 89/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1121 - accuracy: 0.9655\n",
      "Epoch 00089: val_loss did not improve from 0.15024\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1120 - accuracy: 0.9667 - val_loss: 0.1507 - val_accuracy: 0.8000\n",
      "Epoch 90/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1097 - accuracy: 0.9661\n",
      "Epoch 00090: val_loss did not improve from 0.15024\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1119 - accuracy: 0.9667 - val_loss: 0.1512 - val_accuracy: 0.8000\n",
      "Epoch 91/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1180 - accuracy: 0.9636\n",
      "Epoch 00091: val_loss improved from 0.15024 to 0.14999, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1118 - accuracy: 0.9667 - val_loss: 0.1500 - val_accuracy: 0.8000\n",
      "Epoch 92/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1152 - accuracy: 0.9643\n",
      "Epoch 00092: val_loss did not improve from 0.14999\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1118 - accuracy: 0.9667 - val_loss: 0.1500 - val_accuracy: 0.8000\n",
      "Epoch 93/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1063 - accuracy: 0.9636\n",
      "Epoch 00093: val_loss improved from 0.14999 to 0.14989, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1118 - accuracy: 0.9667 - val_loss: 0.1499 - val_accuracy: 0.8000\n",
      "Epoch 94/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1140 - accuracy: 0.9636\n",
      "Epoch 00094: val_loss improved from 0.14989 to 0.14982, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1117 - accuracy: 0.9667 - val_loss: 0.1498 - val_accuracy: 0.8000\n",
      "Epoch 95/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1139 - accuracy: 0.9636\n",
      "Epoch 00095: val_loss did not improve from 0.14982\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1116 - accuracy: 0.9667 - val_loss: 0.1499 - val_accuracy: 0.8000\n",
      "Epoch 96/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1100 - accuracy: 0.9649\n",
      "Epoch 00096: val_loss did not improve from 0.14982\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1116 - accuracy: 0.9667 - val_loss: 0.1499 - val_accuracy: 0.8000\n",
      "Epoch 97/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1138 - accuracy: 0.9636\n",
      "Epoch 00097: val_loss did not improve from 0.14982\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1116 - accuracy: 0.9667 - val_loss: 0.1501 - val_accuracy: 0.8000\n",
      "Epoch 98/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1040 - accuracy: 0.9630\n",
      "Epoch 00098: val_loss did not improve from 0.14982\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1115 - accuracy: 0.9667 - val_loss: 0.1501 - val_accuracy: 0.8000\n",
      "Epoch 99/175\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9661\n",
      "Epoch 00099: val_loss did not improve from 0.14982\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1115 - accuracy: 0.9667 - val_loss: 0.1501 - val_accuracy: 0.8000\n",
      "Epoch 100/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1060 - accuracy: 0.9649\n",
      "Epoch 00100: val_loss improved from 0.14982 to 0.14969, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1114 - accuracy: 0.9667 - val_loss: 0.1497 - val_accuracy: 0.8000\n",
      "Epoch 101/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1190 - accuracy: 0.9630\n",
      "Epoch 00101: val_loss improved from 0.14969 to 0.14956, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1114 - accuracy: 0.9667 - val_loss: 0.1496 - val_accuracy: 0.8000\n",
      "Epoch 102/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1110 - accuracy: 0.9643\n",
      "Epoch 00102: val_loss did not improve from 0.14956\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1113 - accuracy: 0.9667 - val_loss: 0.1497 - val_accuracy: 0.8000\n",
      "Epoch 103/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.9655\n",
      "Epoch 00103: val_loss did not improve from 0.14956\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1113 - accuracy: 0.9667 - val_loss: 0.1498 - val_accuracy: 0.8000\n",
      "Epoch 104/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1031 - accuracy: 0.9815\n",
      "Epoch 00104: val_loss did not improve from 0.14956\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1112 - accuracy: 0.9833 - val_loss: 0.1497 - val_accuracy: 0.8000\n",
      "Epoch 105/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1095 - accuracy: 0.9825\n",
      "Epoch 00105: val_loss improved from 0.14956 to 0.14949, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1112 - accuracy: 0.9833 - val_loss: 0.1495 - val_accuracy: 0.8000\n",
      "Epoch 106/175\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.1069 - accuracy: 0.9821\n",
      "Epoch 00106: val_loss did not improve from 0.14949\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1111 - accuracy: 0.9667 - val_loss: 0.1495 - val_accuracy: 0.8000\n",
      "Epoch 107/175\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9828\n",
      "Epoch 00107: val_loss improved from 0.14949 to 0.14948, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.1111 - accuracy: 0.9833 - val_loss: 0.1495 - val_accuracy: 0.8000\n",
      "Epoch 108/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1171 - accuracy: 0.9818\n",
      "Epoch 00108: val_loss did not improve from 0.14948\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1110 - accuracy: 0.9833 - val_loss: 0.1495 - val_accuracy: 0.8000\n",
      "Epoch 109/175\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.1130 - accuracy: 0.9649\n",
      "Epoch 00109: val_loss did not improve from 0.14948\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1110 - accuracy: 0.9667 - val_loss: 0.1496 - val_accuracy: 0.8000\n",
      "Epoch 110/175\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.1086 - accuracy: 0.9818\n",
      "Epoch 00110: val_loss did not improve from 0.14948\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1109 - accuracy: 0.9667 - val_loss: 0.1497 - val_accuracy: 0.8000\n",
      "Epoch 111/175\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.1028 - accuracy: 0.9815\n",
      "Epoch 00111: val_loss did not improve from 0.14948\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.1109 - accuracy: 0.9833 - val_loss: 0.1496 - val_accuracy: 0.8000\n",
      "Epoch 00111: early stopping\n"
     ]
    }
   ],
   "source": [
    "\"\"\" train the model \"\"\"\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "siamese.compile(loss=utils.loss(1), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# siamese.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "siamese.summary()\n",
    "history = siamese.fit([x_train_1, x_train_2],\n",
    "    labels_train,\n",
    "    validation_data=([x_val_1, x_val_2], labels_val),\n",
    "    batch_size=1,\n",
    "    epochs=175,   # 175 for contrastive 100 for cross ent\n",
    "    callbacks = [checkpointer, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5219b8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "utils.plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdb37692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the constrastive loss\n",
    "utils.plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ebb1ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296/1296 [==============================] - 5s 4ms/sample - loss: 0.1266 - accuracy: 0.9066\n",
      "test loss, test acc: [0.1266104229438452, 0.9066358]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Test the model \"\"\"\n",
    "results = siamese.evaluate([x_test_1, x_test_2], labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be00d433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25254148, 0.16936485, 0.54041904, ..., 0.08060395, 0.5334354 ,\n",
       "       0.03527433], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = siamese.predict([x_test_1, x_test_2]).squeeze()\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4ec4ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred = Y_pred > .5\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f3303c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = labels_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c08c7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on test data\n",
      "Accuracy: 0.9066358024691358\n",
      "Precision: 0.9213263979193758\n",
      "Recall: 0.9066358024691358\n",
      "ROC AUC: 0.9066358024691358\n",
      "F1: 0.9058148020240544\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluate on test data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3661b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)    \n",
    "# cm_display = ConfusionMatrixDisplay(cm, labels_test).plot()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10419799",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ff4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
