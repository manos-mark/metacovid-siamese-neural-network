{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9bc068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0927a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.1.0\n",
      "\t• tf.keras version: 2.2.4-tf\n",
      "\t• Running on GPU\n"
     ]
    }
   ],
   "source": [
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f60667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 3 classes.\n",
      "The train set contains 30\n",
      "Found 30 images belonging to 3 classes.\n",
      "The valid set contains 30\n",
      "Found 648 images belonging to 3 classes.\n",
      "The test set contains 648\n"
     ]
    }
   ],
   "source": [
    "basedir = os.path.join(\"C:\\\\Users\\\\aktas\\\\Desktop\\\\VIBOT\\\\3.semester\\\\Meta-Learning\\\\project_final\\\\metacovid-siamese-neural-network\", \"dataset\", \"siamese\") \n",
    "\n",
    "train_image_list, train_y_list = utils.load_images(basedir, 'train', (100,100))\n",
    "print(\"The train set contains\",len(train_image_list)) \n",
    "\n",
    "valid_image_list, valid_y_list = utils.load_images(basedir, 'validation', (100,100))   \n",
    "print(\"The valid set contains\", len(valid_image_list))  \n",
    "\n",
    "test_image_list, test_y_list = utils.load_images(basedir, 'test', (100,100))   \n",
    "print(\"The test set contains\", len(test_image_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a873fba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs for training 60\n",
      "number of pairs for validation 60\n",
      "number of pairs for test 1296\n"
     ]
    }
   ],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train = utils.make_pairs(train_image_list, train_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_val, labels_val = utils.make_pairs(valid_image_list, valid_y_list)\n",
    "\n",
    "# make test pairs\n",
    "pairs_test, labels_test = utils.make_pairs(test_image_list, test_y_list)\n",
    "\n",
    "x_train_1 = pairs_train[:, 0]  \n",
    "x_train_2 = pairs_train[:, 1]\n",
    "print(\"number of pairs for training\", np.shape(x_train_1)[0]) \n",
    "\n",
    "x_val_1 = pairs_val[:, 0] \n",
    "x_val_2 = pairs_val[:, 1]\n",
    "print(\"number of pairs for validation\", np.shape(x_val_1)[0]) \n",
    "\n",
    "x_test_1 = pairs_test[:, 0] \n",
    "x_test_2 = pairs_test[:, 1]\n",
    "print(\"number of pairs for test\", np.shape(x_test_1)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b9dade0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 5120)         14748995    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "SIAMESE_MODEL_FNAME = 'siamese_network.h5'\n",
    "EMBEDDING_MODEL_FNAME = 'embedding_network.h5'\n",
    "\n",
    "input_1 = Input((100,100,3))\n",
    "input_2 = Input((100,100,3))\n",
    "\n",
    "embedding_network = tf.keras.models.load_model(EMBEDDING_MODEL_FNAME)\n",
    "embedding_network.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential() \n",
    "for layer in embedding_network.layers:  \n",
    "    model.add(layer) \n",
    "\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dense(5120, name='den', activation='sigmoid', kernel_regularizer='l2')) \n",
    " \n",
    "output_1 = model(input_1) \n",
    "output_2 = model(input_2) \n",
    " \n",
    "merge_layer = Lambda(utils.manhattan_distance)([output_1, output_2]) \n",
    "output_layer = Dense(1, activation=\"sigmoid\")(merge_layer) \n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer) \n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b4a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" callbacks \"\"\"\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.0001)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='siamese_network.h5', verbose=1, \n",
    "                                save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5b21af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 5120)         14748995    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.6382 - accuracy: 0.5636\n",
      "Epoch 00001: val_loss improved from inf to 0.63120, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 4s 67ms/sample - loss: 0.6350 - accuracy: 0.5500 - val_loss: 0.6312 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.6118 - accuracy: 0.6727\n",
      "Epoch 00002: val_loss improved from 0.63120 to 0.61951, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.6175 - accuracy: 0.6833 - val_loss: 0.6195 - val_accuracy: 0.6500\n",
      "Epoch 3/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.6094 - accuracy: 0.7407\n",
      "Epoch 00003: val_loss improved from 0.61951 to 0.61371, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.6090 - accuracy: 0.7500 - val_loss: 0.6137 - val_accuracy: 0.7000\n",
      "Epoch 4/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.6068 - accuracy: 0.8364\n",
      "Epoch 00004: val_loss improved from 0.61371 to 0.61057, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.6048 - accuracy: 0.8333 - val_loss: 0.6106 - val_accuracy: 0.7000\n",
      "Epoch 5/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.6066 - accuracy: 0.8621\n",
      "Epoch 00005: val_loss improved from 0.61057 to 0.60875, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.6025 - accuracy: 0.8667 - val_loss: 0.6087 - val_accuracy: 0.7167\n",
      "Epoch 6/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.6118 - accuracy: 0.8909\n",
      "Epoch 00006: val_loss improved from 0.60875 to 0.60774, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.6011 - accuracy: 0.8667 - val_loss: 0.6077 - val_accuracy: 0.7333\n",
      "Epoch 7/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5975 - accuracy: 0.9091\n",
      "Epoch 00007: val_loss improved from 0.60774 to 0.60690, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.6001 - accuracy: 0.9000 - val_loss: 0.6069 - val_accuracy: 0.7333\n",
      "Epoch 8/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5974 - accuracy: 0.8983\n",
      "Epoch 00008: val_loss improved from 0.60690 to 0.60632, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5994 - accuracy: 0.9000 - val_loss: 0.6063 - val_accuracy: 0.7833\n",
      "Epoch 9/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5884 - accuracy: 0.8909\n",
      "Epoch 00009: val_loss improved from 0.60632 to 0.60590, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5989 - accuracy: 0.9000 - val_loss: 0.6059 - val_accuracy: 0.7833\n",
      "Epoch 10/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5964 - accuracy: 0.9153\n",
      "Epoch 00010: val_loss improved from 0.60590 to 0.60536, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5983 - accuracy: 0.9167 - val_loss: 0.6054 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5980 - accuracy: 0.9138\n",
      "Epoch 00011: val_loss improved from 0.60536 to 0.60495, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5979 - accuracy: 0.9167 - val_loss: 0.6050 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5975 - accuracy: 0.9107\n",
      "Epoch 00012: val_loss improved from 0.60495 to 0.60459, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5975 - accuracy: 0.9167 - val_loss: 0.6046 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5951 - accuracy: 0.9153\n",
      "Epoch 00013: val_loss improved from 0.60459 to 0.60418, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5970 - accuracy: 0.9167 - val_loss: 0.6042 - val_accuracy: 0.8167\n",
      "Epoch 14/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.6098 - accuracy: 0.9074\n",
      "Epoch 00014: val_loss improved from 0.60418 to 0.60388, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5967 - accuracy: 0.9167 - val_loss: 0.6039 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5967 - accuracy: 0.9074\n",
      "Epoch 00015: val_loss improved from 0.60388 to 0.60339, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5965 - accuracy: 0.9167 - val_loss: 0.6034 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5942 - accuracy: 0.9123\n",
      "Epoch 00016: val_loss improved from 0.60339 to 0.60326, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5960 - accuracy: 0.9167 - val_loss: 0.6033 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5978 - accuracy: 0.9298\n",
      "Epoch 00017: val_loss improved from 0.60326 to 0.60285, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5956 - accuracy: 0.9333 - val_loss: 0.6029 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5934 - accuracy: 0.9322\n",
      "Epoch 00018: val_loss improved from 0.60285 to 0.60234, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5953 - accuracy: 0.9333 - val_loss: 0.6023 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.6012 - accuracy: 0.9298\n",
      "Epoch 00019: val_loss improved from 0.60234 to 0.60217, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5950 - accuracy: 0.9333 - val_loss: 0.6022 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5927 - accuracy: 0.9298\n",
      "Epoch 00020: val_loss improved from 0.60217 to 0.60182, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5947 - accuracy: 0.9333 - val_loss: 0.6018 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5923 - accuracy: 0.9298\n",
      "Epoch 00021: val_loss improved from 0.60182 to 0.60146, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5943 - accuracy: 0.9333 - val_loss: 0.6015 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5920 - accuracy: 0.9322\n",
      "Epoch 00022: val_loss improved from 0.60146 to 0.60117, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5940 - accuracy: 0.9333 - val_loss: 0.6012 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5909 - accuracy: 0.9636\n",
      "Epoch 00023: val_loss improved from 0.60117 to 0.60078, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 22ms/sample - loss: 0.5938 - accuracy: 0.9333 - val_loss: 0.6008 - val_accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5935 - accuracy: 0.9310\n",
      "Epoch 00024: val_loss improved from 0.60078 to 0.60058, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5934 - accuracy: 0.9333 - val_loss: 0.6006 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.6020 - accuracy: 0.9259\n",
      "Epoch 00025: val_loss improved from 0.60058 to 0.60013, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5931 - accuracy: 0.9333 - val_loss: 0.6001 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5929 - accuracy: 0.9310\n",
      "Epoch 00026: val_loss improved from 0.60013 to 0.59993, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5928 - accuracy: 0.9333 - val_loss: 0.5999 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5919 - accuracy: 0.9444\n",
      "Epoch 00027: val_loss improved from 0.59993 to 0.59955, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5925 - accuracy: 0.9333 - val_loss: 0.5996 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5903 - accuracy: 0.9298\n",
      "Epoch 00028: val_loss did not improve from 0.59955\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.5922 - accuracy: 0.9333 - val_loss: 0.5997 - val_accuracy: 0.8500\n",
      "Epoch 29/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5921 - accuracy: 0.9310\n",
      "Epoch 00029: val_loss improved from 0.59955 to 0.59913, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5921 - accuracy: 0.9333 - val_loss: 0.5991 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5855 - accuracy: 0.9273\n",
      "Epoch 00030: val_loss improved from 0.59913 to 0.59873, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5918 - accuracy: 0.9333 - val_loss: 0.5987 - val_accuracy: 0.8500\n",
      "Epoch 31/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5895 - accuracy: 0.9322\n",
      "Epoch 00031: val_loss improved from 0.59873 to 0.59833, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5914 - accuracy: 0.9333 - val_loss: 0.5983 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5950 - accuracy: 0.9483\n",
      "Epoch 00032: val_loss improved from 0.59833 to 0.59823, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5911 - accuracy: 0.9333 - val_loss: 0.5982 - val_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5929 - accuracy: 0.9474\n",
      "Epoch 00033: val_loss improved from 0.59823 to 0.59796, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5909 - accuracy: 0.9333 - val_loss: 0.5980 - val_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5929 - accuracy: 0.9273\n",
      "Epoch 00034: val_loss improved from 0.59796 to 0.59767, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5905 - accuracy: 0.9333 - val_loss: 0.5977 - val_accuracy: 0.8500\n",
      "Epoch 35/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5903 - accuracy: 0.9286\n",
      "Epoch 00035: val_loss improved from 0.59767 to 0.59740, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5902 - accuracy: 0.9333 - val_loss: 0.5974 - val_accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5924 - accuracy: 0.9273\n",
      "Epoch 00036: val_loss improved from 0.59740 to 0.59711, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5900 - accuracy: 0.9333 - val_loss: 0.5971 - val_accuracy: 0.8500\n",
      "Epoch 37/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5878 - accuracy: 0.9298\n",
      "Epoch 00037: val_loss improved from 0.59711 to 0.59687, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5897 - accuracy: 0.9333 - val_loss: 0.5969 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5936 - accuracy: 0.9310\n",
      "Epoch 00038: val_loss improved from 0.59687 to 0.59665, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5894 - accuracy: 0.9333 - val_loss: 0.5967 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5871 - accuracy: 0.9298\n",
      "Epoch 00039: val_loss improved from 0.59665 to 0.59648, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5892 - accuracy: 0.9333 - val_loss: 0.5965 - val_accuracy: 0.8667\n",
      "Epoch 40/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5935 - accuracy: 0.9259\n",
      "Epoch 00040: val_loss improved from 0.59648 to 0.59624, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5889 - accuracy: 0.9333 - val_loss: 0.5962 - val_accuracy: 0.8667\n",
      "Epoch 41/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5867 - accuracy: 0.9273\n",
      "Epoch 00041: val_loss improved from 0.59624 to 0.59584, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5887 - accuracy: 0.9333 - val_loss: 0.5958 - val_accuracy: 0.8667\n",
      "Epoch 42/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5897 - accuracy: 0.9492\n",
      "Epoch 00042: val_loss improved from 0.59584 to 0.59557, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5884 - accuracy: 0.9333 - val_loss: 0.5956 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5902 - accuracy: 0.9322\n",
      "Epoch 00043: val_loss improved from 0.59557 to 0.59539, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5881 - accuracy: 0.9333 - val_loss: 0.5954 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5911 - accuracy: 0.9655\n",
      "Epoch 00044: val_loss improved from 0.59539 to 0.59533, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5879 - accuracy: 0.9333 - val_loss: 0.5953 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5834 - accuracy: 0.9259\n",
      "Epoch 00045: val_loss improved from 0.59533 to 0.59507, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5877 - accuracy: 0.9333 - val_loss: 0.5951 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5853 - accuracy: 0.9298\n",
      "Epoch 00046: val_loss improved from 0.59507 to 0.59461, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5874 - accuracy: 0.9333 - val_loss: 0.5946 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5885 - accuracy: 0.9474\n",
      "Epoch 00047: val_loss improved from 0.59461 to 0.59431, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5872 - accuracy: 0.9333 - val_loss: 0.5943 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5850 - accuracy: 0.9322\n",
      "Epoch 00048: val_loss improved from 0.59431 to 0.59420, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5869 - accuracy: 0.9333 - val_loss: 0.5942 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5906 - accuracy: 0.9444\n",
      "Epoch 00049: val_loss improved from 0.59420 to 0.59364, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5867 - accuracy: 0.9333 - val_loss: 0.5936 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5845 - accuracy: 0.9661\n",
      "Epoch 00050: val_loss did not improve from 0.59364\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.5864 - accuracy: 0.9667 - val_loss: 0.5937 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5863 - accuracy: 0.9310\n",
      "Epoch 00051: val_loss improved from 0.59364 to 0.59358, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5862 - accuracy: 0.9333 - val_loss: 0.5936 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5909 - accuracy: 0.9630\n",
      "Epoch 00052: val_loss improved from 0.59358 to 0.59318, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5861 - accuracy: 0.9667 - val_loss: 0.5932 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5969 - accuracy: 0.9273\n",
      "Epoch 00053: val_loss improved from 0.59318 to 0.59311, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5857 - accuracy: 0.9333 - val_loss: 0.5931 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5857 - accuracy: 0.9643\n",
      "Epoch 00054: val_loss improved from 0.59311 to 0.59295, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5855 - accuracy: 0.9667 - val_loss: 0.5930 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5833 - accuracy: 0.9661\n",
      "Epoch 00055: val_loss improved from 0.59295 to 0.59266, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5853 - accuracy: 0.9667 - val_loss: 0.5927 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5872 - accuracy: 0.9661\n",
      "Epoch 00056: val_loss improved from 0.59266 to 0.59218, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5851 - accuracy: 0.9667 - val_loss: 0.5922 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5884 - accuracy: 0.9821\n",
      "Epoch 00057: val_loss improved from 0.59218 to 0.59211, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5848 - accuracy: 0.9667 - val_loss: 0.5921 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5861 - accuracy: 0.9825\n",
      "Epoch 00058: val_loss improved from 0.59211 to 0.59178, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5846 - accuracy: 0.9667 - val_loss: 0.5918 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5844 - accuracy: 0.9655\n",
      "Epoch 00059: val_loss improved from 0.59178 to 0.59176, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5843 - accuracy: 0.9667 - val_loss: 0.5918 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5812 - accuracy: 0.9825\n",
      "Epoch 00060: val_loss improved from 0.59176 to 0.59128, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5841 - accuracy: 0.9667 - val_loss: 0.5913 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5839 - accuracy: 0.9655\n",
      "Epoch 00061: val_loss improved from 0.59128 to 0.59122, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5838 - accuracy: 0.9667 - val_loss: 0.5912 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5834 - accuracy: 0.9655\n",
      "Epoch 00062: val_loss improved from 0.59122 to 0.59085, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5836 - accuracy: 0.9667 - val_loss: 0.5909 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5922 - accuracy: 0.9643\n",
      "Epoch 00063: val_loss did not improve from 0.59085\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.5834 - accuracy: 0.9667 - val_loss: 0.5910 - val_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5834 - accuracy: 0.9643\n",
      "Epoch 00064: val_loss improved from 0.59085 to 0.59058, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5832 - accuracy: 0.9667 - val_loss: 0.5906 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5831 - accuracy: 0.9643\n",
      "Epoch 00065: val_loss improved from 0.59058 to 0.59003, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5829 - accuracy: 0.9667 - val_loss: 0.5900 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5848 - accuracy: 0.9661\n",
      "Epoch 00066: val_loss did not improve from 0.59003\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.5827 - accuracy: 0.9667 - val_loss: 0.5903 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5844 - accuracy: 0.9649\n",
      "Epoch 00067: val_loss improved from 0.59003 to 0.58982, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5825 - accuracy: 0.9667 - val_loss: 0.5898 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5886 - accuracy: 0.9649\n",
      "Epoch 00068: val_loss improved from 0.58982 to 0.58971, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5823 - accuracy: 0.9667 - val_loss: 0.5897 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5822 - accuracy: 0.9643\n",
      "Epoch 00069: val_loss improved from 0.58971 to 0.58936, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5820 - accuracy: 0.9667 - val_loss: 0.5894 - val_accuracy: 0.8667\n",
      "Epoch 70/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5821 - accuracy: 0.9630\n",
      "Epoch 00070: val_loss improved from 0.58936 to 0.58927, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5818 - accuracy: 0.9667 - val_loss: 0.5893 - val_accuracy: 0.8667\n",
      "Epoch 71/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5816 - accuracy: 0.9655\n",
      "Epoch 00071: val_loss did not improve from 0.58927\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.5815 - accuracy: 0.9667 - val_loss: 0.5893 - val_accuracy: 0.8667\n",
      "Epoch 72/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5793 - accuracy: 0.9661\n",
      "Epoch 00072: val_loss improved from 0.58927 to 0.58870, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5814 - accuracy: 0.9667 - val_loss: 0.5887 - val_accuracy: 0.8667\n",
      "Epoch 73/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5813 - accuracy: 0.9655\n",
      "Epoch 00073: val_loss improved from 0.58870 to 0.58832, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5811 - accuracy: 0.9667 - val_loss: 0.5883 - val_accuracy: 0.8667\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/60 [============================>.] - ETA: 0s - loss: 0.5845 - accuracy: 0.9828\n",
      "Epoch 00074: val_loss improved from 0.58832 to 0.58822, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5810 - accuracy: 0.9667 - val_loss: 0.5882 - val_accuracy: 0.8667\n",
      "Epoch 75/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5851 - accuracy: 0.9655\n",
      "Epoch 00075: val_loss improved from 0.58822 to 0.58801, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5807 - accuracy: 0.9667 - val_loss: 0.5880 - val_accuracy: 0.8667\n",
      "Epoch 76/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5763 - accuracy: 0.9643\n",
      "Epoch 00076: val_loss improved from 0.58801 to 0.58771, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5805 - accuracy: 0.9667 - val_loss: 0.5877 - val_accuracy: 0.8667\n",
      "Epoch 77/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5824 - accuracy: 0.9661\n",
      "Epoch 00077: val_loss improved from 0.58771 to 0.58747, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5802 - accuracy: 0.9667 - val_loss: 0.5875 - val_accuracy: 0.8667\n",
      "Epoch 78/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5847 - accuracy: 0.9643\n",
      "Epoch 00078: val_loss improved from 0.58747 to 0.58711, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5801 - accuracy: 0.9667 - val_loss: 0.5871 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5820 - accuracy: 0.9661\n",
      "Epoch 00079: val_loss did not improve from 0.58711\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.5798 - accuracy: 0.9667 - val_loss: 0.5874 - val_accuracy: 0.9000\n",
      "Epoch 80/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5797 - accuracy: 0.9655\n",
      "Epoch 00080: val_loss improved from 0.58711 to 0.58707, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5796 - accuracy: 0.9667 - val_loss: 0.5871 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5749 - accuracy: 0.9630\n",
      "Epoch 00081: val_loss improved from 0.58707 to 0.58677, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5794 - accuracy: 0.9667 - val_loss: 0.5868 - val_accuracy: 0.9500\n",
      "Epoch 82/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5830 - accuracy: 0.9821\n",
      "Epoch 00082: val_loss improved from 0.58677 to 0.58663, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5792 - accuracy: 0.9667 - val_loss: 0.5866 - val_accuracy: 0.8667\n",
      "Epoch 83/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5811 - accuracy: 0.9661\n",
      "Epoch 00083: val_loss improved from 0.58663 to 0.58659, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5789 - accuracy: 0.9667 - val_loss: 0.5866 - val_accuracy: 0.9333\n",
      "Epoch 84/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5745 - accuracy: 0.9655\n",
      "Epoch 00084: val_loss improved from 0.58659 to 0.58601, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5788 - accuracy: 0.9667 - val_loss: 0.5860 - val_accuracy: 0.9500\n",
      "Epoch 85/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5784 - accuracy: 0.9643\n",
      "Epoch 00085: val_loss improved from 0.58601 to 0.58587, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5785 - accuracy: 0.9667 - val_loss: 0.5859 - val_accuracy: 0.9500\n",
      "Epoch 86/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5829 - accuracy: 0.9655\n",
      "Epoch 00086: val_loss improved from 0.58587 to 0.58574, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5785 - accuracy: 0.9667 - val_loss: 0.5857 - val_accuracy: 0.9000\n",
      "Epoch 87/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5796 - accuracy: 0.9825\n",
      "Epoch 00087: val_loss improved from 0.58574 to 0.58560, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5782 - accuracy: 0.9667 - val_loss: 0.5856 - val_accuracy: 0.9333\n",
      "Epoch 88/100\n",
      "54/60 [==========================>...] - ETA: 0s - loss: 0.5736 - accuracy: 0.9630\n",
      "Epoch 00088: val_loss did not improve from 0.58560\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.5779 - accuracy: 0.9667 - val_loss: 0.5857 - val_accuracy: 0.9500\n",
      "Epoch 89/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5836 - accuracy: 0.9825\n",
      "Epoch 00089: val_loss improved from 0.58560 to 0.58514, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5777 - accuracy: 0.9667 - val_loss: 0.5851 - val_accuracy: 0.9500\n",
      "Epoch 90/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5732 - accuracy: 0.9655\n",
      "Epoch 00090: val_loss did not improve from 0.58514\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.5775 - accuracy: 0.9667 - val_loss: 0.5852 - val_accuracy: 0.9500\n",
      "Epoch 91/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5798 - accuracy: 0.9636\n",
      "Epoch 00091: val_loss improved from 0.58514 to 0.58481, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5773 - accuracy: 0.9667 - val_loss: 0.5848 - val_accuracy: 0.9500\n",
      "Epoch 92/100\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.9655\n",
      "Epoch 00092: val_loss improved from 0.58481 to 0.58432, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5771 - accuracy: 0.9667 - val_loss: 0.5843 - val_accuracy: 0.9500\n",
      "Epoch 93/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5749 - accuracy: 0.9661\n",
      "Epoch 00093: val_loss did not improve from 0.58432\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.5770 - accuracy: 0.9667 - val_loss: 0.5844 - val_accuracy: 0.9500\n",
      "Epoch 94/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5789 - accuracy: 0.9661\n",
      "Epoch 00094: val_loss improved from 0.58432 to 0.58399, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5767 - accuracy: 0.9667 - val_loss: 0.5840 - val_accuracy: 0.9500\n",
      "Epoch 95/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5699 - accuracy: 0.9649\n",
      "Epoch 00095: val_loss did not improve from 0.58399\n",
      "60/60 [==============================] - 1s 20ms/sample - loss: 0.5765 - accuracy: 0.9667 - val_loss: 0.5844 - val_accuracy: 0.9500\n",
      "Epoch 96/100\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.5742 - accuracy: 0.9661\n",
      "Epoch 00096: val_loss improved from 0.58399 to 0.58383, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5764 - accuracy: 0.9667 - val_loss: 0.5838 - val_accuracy: 0.9500\n",
      "Epoch 97/100\n",
      "57/60 [===========================>..] - ETA: 0s - loss: 0.5741 - accuracy: 0.9649\n",
      "Epoch 00097: val_loss improved from 0.58383 to 0.58351, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5762 - accuracy: 0.9667 - val_loss: 0.5835 - val_accuracy: 0.9500\n",
      "Epoch 98/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5798 - accuracy: 0.9821\n",
      "Epoch 00098: val_loss improved from 0.58351 to 0.58327, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5759 - accuracy: 0.9667 - val_loss: 0.5833 - val_accuracy: 0.9500\n",
      "Epoch 99/100\n",
      "55/60 [==========================>...] - ETA: 0s - loss: 0.5783 - accuracy: 0.9636\n",
      "Epoch 00099: val_loss improved from 0.58327 to 0.58325, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 21ms/sample - loss: 0.5757 - accuracy: 0.9667 - val_loss: 0.5833 - val_accuracy: 0.9500\n",
      "Epoch 100/100\n",
      "56/60 [===========================>..] - ETA: 0s - loss: 0.5665 - accuracy: 0.9643\n",
      "Epoch 00100: val_loss improved from 0.58325 to 0.58323, saving model to siamese_network.h5\n",
      "60/60 [==============================] - 1s 22ms/sample - loss: 0.5755 - accuracy: 0.9667 - val_loss: 0.5832 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "\"\"\" train the model \"\"\"\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "siamese.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# siamese.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "siamese.summary()\n",
    "history = siamese.fit([x_train_1, x_train_2],\n",
    "    labels_train,\n",
    "    validation_data=([x_val_1, x_val_2], labels_val),\n",
    "    batch_size=1,\n",
    "    epochs=100,   # 175 for contrastive 100 for cross ent\n",
    "    callbacks = [checkpointer, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5219b8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "utils.plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdb37692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the cross entropy binary loss\n",
    "utils.plt_metric(history=history.history, metric=\"loss\", title=\"Binary Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ebb1ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296/1296 [==============================] - 3s 2ms/sample - loss: 0.5848 - accuracy: 0.9290\n",
      "test loss, test acc: [0.5847931128961069, 0.92901236]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Test the model \"\"\"\n",
    "results = siamese.evaluate([x_test_1, x_test_2], labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be00d433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35574326, 0.02214266, 0.5947736 , ..., 0.01073599, 0.58562875,\n",
       "       0.0073857 ], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = siamese.predict([x_test_1, x_test_2]).squeeze()\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6adf7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27663705"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4ec4ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred = Y_pred > Y_pred.mean()\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f3303c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = labels_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c08c7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on test data\n",
      "Accuracy: 0.9683641975308642\n",
      "Precision: 0.9694385632413001\n",
      "Recall: 0.9683641975308642\n",
      "ROC AUC: 0.9683641975308642\n",
      "F1: 0.9683460865990928\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluate on test data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3661b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9922839506172839\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)    \n",
    "# cm_display = ConfusionMatrixDisplay(cm, labels_test).plot()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10419799",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ff4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
