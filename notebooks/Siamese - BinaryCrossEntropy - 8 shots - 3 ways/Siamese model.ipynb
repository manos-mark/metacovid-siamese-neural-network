{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc42bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde1ea84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.1.0\n",
      "\t• tf.keras version: 2.2.4-tf\n",
      "\t• Running on GPU\n"
     ]
    }
   ],
   "source": [
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e983b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 images belonging to 3 classes.\n",
      "The train set contains 24\n",
      "Found 24 images belonging to 3 classes.\n",
      "The valid set contains 24\n",
      "Found 648 images belonging to 3 classes.\n",
      "The test set contains 648\n"
     ]
    }
   ],
   "source": [
    "basedir = os.path.join(\"C:\\\\Users\\\\aktas\\\\Desktop\\\\VIBOT\\\\3.semester\\\\Meta-Learning\\\\project_final\\\\metacovid-siamese-neural-network\", \"dataset\", \"siamese\") \n",
    "\n",
    "train_image_list, train_y_list = utils.load_images(basedir, 'train', (100,100))\n",
    "print(\"The train set contains\",len(train_image_list)) \n",
    "\n",
    "valid_image_list, valid_y_list = utils.load_images(basedir, 'validation', (100,100))   \n",
    "print(\"The valid set contains\", len(valid_image_list))  \n",
    "\n",
    "test_image_list, test_y_list = utils.load_images(basedir, 'test', (100,100))   \n",
    "print(\"The test set contains\", len(test_image_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e510ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs for training 48\n",
      "number of pairs for validation 48\n",
      "number of pairs for test 1296\n"
     ]
    }
   ],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train = utils.make_pairs(train_image_list, train_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_val, labels_val = utils.make_pairs(valid_image_list, valid_y_list)\n",
    "\n",
    "# make test pairs\n",
    "pairs_test, labels_test = utils.make_pairs(test_image_list, test_y_list)\n",
    "\n",
    "x_train_1 = pairs_train[:, 0]  \n",
    "x_train_2 = pairs_train[:, 1]\n",
    "print(\"number of pairs for training\", np.shape(x_train_1)[0]) \n",
    "\n",
    "x_val_1 = pairs_val[:, 0] \n",
    "x_val_2 = pairs_val[:, 1]\n",
    "print(\"number of pairs for validation\", np.shape(x_val_1)[0]) \n",
    "\n",
    "x_test_1 = pairs_test[:, 0] \n",
    "x_test_2 = pairs_test[:, 1]\n",
    "print(\"number of pairs for test\", np.shape(x_test_1)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ab81282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 5120)         14748995    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "SIAMESE_MODEL_FNAME = 'siamese_network.h5'\n",
    "EMBEDDING_MODEL_FNAME = 'embedding_network.h5'\n",
    "\n",
    "input_1 = Input((100,100,3))\n",
    "input_2 = Input((100,100,3))\n",
    "\n",
    "embedding_network = tf.keras.models.load_model(EMBEDDING_MODEL_FNAME)\n",
    "embedding_network.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential() \n",
    "for layer in embedding_network.layers:  \n",
    "    model.add(layer) \n",
    "\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dense(5120, name='den', activation='sigmoid', kernel_regularizer='l2')) \n",
    " \n",
    "output_1 = model(input_1) \n",
    "output_2 = model(input_2) \n",
    " \n",
    "merge_layer = Lambda(utils.manhattan_distance)([output_1, output_2]) \n",
    "output_layer = Dense(1, activation=\"sigmoid\")(merge_layer) \n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer) \n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84bde165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" callbacks \"\"\"\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.0001)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='siamese_network.h5', verbose=1, \n",
    "                                save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa63961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 5120)         14748995    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n",
      "Train on 48 samples, validate on 48 samples\n",
      "Epoch 1/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.6379 - accuracy: 0.5814\n",
      "Epoch 00001: val_loss improved from inf to 0.64688, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 4s 77ms/sample - loss: 0.6388 - accuracy: 0.5833 - val_loss: 0.6469 - val_accuracy: 0.6042\n",
      "Epoch 2/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.6163 - accuracy: 0.5714\n",
      "Epoch 00002: val_loss improved from 0.64688 to 0.63032, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.6201 - accuracy: 0.6250 - val_loss: 0.6303 - val_accuracy: 0.6250\n",
      "Epoch 3/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.6061 - accuracy: 0.6279\n",
      "Epoch 00003: val_loss improved from 0.63032 to 0.62009, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.6079 - accuracy: 0.6667 - val_loss: 0.6201 - val_accuracy: 0.6458\n",
      "Epoch 4/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.6063 - accuracy: 0.7143\n",
      "Epoch 00004: val_loss improved from 0.62009 to 0.61492, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.6009 - accuracy: 0.6875 - val_loss: 0.6149 - val_accuracy: 0.6458\n",
      "Epoch 5/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5995 - accuracy: 0.7907\n",
      "Epoch 00005: val_loss improved from 0.61492 to 0.61246, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5974 - accuracy: 0.7708 - val_loss: 0.6125 - val_accuracy: 0.6458\n",
      "Epoch 6/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5953 - accuracy: 0.8095\n",
      "Epoch 00006: val_loss improved from 0.61246 to 0.61082, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5954 - accuracy: 0.7917 - val_loss: 0.6108 - val_accuracy: 0.6458\n",
      "Epoch 7/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.6050 - accuracy: 0.8571\n",
      "Epoch 00007: val_loss improved from 0.61082 to 0.61028, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5943 - accuracy: 0.8333 - val_loss: 0.6103 - val_accuracy: 0.6458\n",
      "Epoch 8/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5956 - accuracy: 0.8511\n",
      "Epoch 00008: val_loss improved from 0.61028 to 0.60961, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5935 - accuracy: 0.8333 - val_loss: 0.6096 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5906 - accuracy: 0.8140\n",
      "Epoch 00009: val_loss improved from 0.60961 to 0.60925, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5930 - accuracy: 0.8333 - val_loss: 0.6093 - val_accuracy: 0.6875\n",
      "Epoch 10/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5931 - accuracy: 0.8095\n",
      "Epoch 00010: val_loss improved from 0.60925 to 0.60889, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5928 - accuracy: 0.8333 - val_loss: 0.6089 - val_accuracy: 0.7083\n",
      "Epoch 11/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5900 - accuracy: 0.8140\n",
      "Epoch 00011: val_loss improved from 0.60889 to 0.60863, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5924 - accuracy: 0.8333 - val_loss: 0.6086 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5898 - accuracy: 0.8298\n",
      "Epoch 00012: val_loss improved from 0.60863 to 0.60861, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5921 - accuracy: 0.8333 - val_loss: 0.6086 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5976 - accuracy: 0.8095\n",
      "Epoch 00013: val_loss improved from 0.60861 to 0.60850, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5919 - accuracy: 0.8333 - val_loss: 0.6085 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5920 - accuracy: 0.8095\n",
      "Epoch 00014: val_loss improved from 0.60850 to 0.60813, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5916 - accuracy: 0.8333 - val_loss: 0.6081 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5942 - accuracy: 0.8605\n",
      "Epoch 00015: val_loss did not improve from 0.60813\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 0.5915 - accuracy: 0.8542 - val_loss: 0.6082 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5751 - accuracy: 0.8333\n",
      "Epoch 00016: val_loss improved from 0.60813 to 0.60791, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5912 - accuracy: 0.8542 - val_loss: 0.6079 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5882 - accuracy: 0.8605\n",
      "Epoch 00017: val_loss improved from 0.60791 to 0.60762, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5909 - accuracy: 0.8542 - val_loss: 0.6076 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "45/48 [===========================>..] - ETA: 0s - loss: 0.5981 - accuracy: 0.8667\n",
      "Epoch 00018: val_loss improved from 0.60762 to 0.60731, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5908 - accuracy: 0.8542 - val_loss: 0.6073 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5932 - accuracy: 0.8511\n",
      "Epoch 00019: val_loss improved from 0.60731 to 0.60710, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5906 - accuracy: 0.8542 - val_loss: 0.6071 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5881 - accuracy: 0.8372\n",
      "Epoch 00020: val_loss did not improve from 0.60710\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 0.5905 - accuracy: 0.8542 - val_loss: 0.6072 - val_accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5850 - accuracy: 0.8333\n",
      "Epoch 00021: val_loss improved from 0.60710 to 0.60688, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5903 - accuracy: 0.8542 - val_loss: 0.6069 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5873 - accuracy: 0.8605\n",
      "Epoch 00022: val_loss improved from 0.60688 to 0.60640, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5901 - accuracy: 0.8542 - val_loss: 0.6064 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5920 - accuracy: 0.8837\n",
      "Epoch 00023: val_loss did not improve from 0.60640\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 0.5899 - accuracy: 0.8542 - val_loss: 0.6064 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5896 - accuracy: 0.8571\n",
      "Epoch 00024: val_loss did not improve from 0.60640\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 0.5896 - accuracy: 0.8542 - val_loss: 0.6064 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5920 - accuracy: 0.8511\n",
      "Epoch 00025: val_loss improved from 0.60640 to 0.60625, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5895 - accuracy: 0.8542 - val_loss: 0.6063 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5943 - accuracy: 0.8810\n",
      "Epoch 00026: val_loss improved from 0.60625 to 0.60621, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5893 - accuracy: 0.8542 - val_loss: 0.6062 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5839 - accuracy: 0.8571\n",
      "Epoch 00027: val_loss improved from 0.60621 to 0.60594, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5891 - accuracy: 0.8750 - val_loss: 0.6059 - val_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5838 - accuracy: 0.8571\n",
      "Epoch 00028: val_loss improved from 0.60594 to 0.60559, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5890 - accuracy: 0.8750 - val_loss: 0.6056 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5947 - accuracy: 0.8571\n",
      "Epoch 00029: val_loss improved from 0.60559 to 0.60544, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5887 - accuracy: 0.8750 - val_loss: 0.6054 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5807 - accuracy: 0.8605\n",
      "Epoch 00030: val_loss did not improve from 0.60544\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 0.5885 - accuracy: 0.8750 - val_loss: 0.6055 - val_accuracy: 0.7500\n",
      "Epoch 31/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5884 - accuracy: 0.8810\n",
      "Epoch 00031: val_loss did not improve from 0.60544\n",
      "48/48 [==============================] - 1s 20ms/sample - loss: 0.5884 - accuracy: 0.8750 - val_loss: 0.6055 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "46/48 [===========================>..] - ETA: 0s - loss: 0.5933 - accuracy: 0.8696\n",
      "Epoch 00032: val_loss improved from 0.60544 to 0.60517, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5881 - accuracy: 0.8750 - val_loss: 0.6052 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5906 - accuracy: 0.8723\n",
      "Epoch 00033: val_loss improved from 0.60517 to 0.60495, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5880 - accuracy: 0.8750 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5853 - accuracy: 0.8605\n",
      "Epoch 00034: val_loss improved from 0.60495 to 0.60494, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5878 - accuracy: 0.8750 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5957 - accuracy: 0.8837\n",
      "Epoch 00035: val_loss improved from 0.60494 to 0.60452, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5876 - accuracy: 0.8750 - val_loss: 0.6045 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.6007 - accuracy: 0.8837\n",
      "Epoch 00036: val_loss improved from 0.60452 to 0.60441, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5875 - accuracy: 0.8750 - val_loss: 0.6044 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5899 - accuracy: 0.8837\n",
      "Epoch 00037: val_loss improved from 0.60441 to 0.60428, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5872 - accuracy: 0.8750 - val_loss: 0.6043 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5844 - accuracy: 0.8837\n",
      "Epoch 00038: val_loss did not improve from 0.60428\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 0.5872 - accuracy: 0.8750 - val_loss: 0.6043 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5941 - accuracy: 0.9302\n",
      "Epoch 00039: val_loss improved from 0.60428 to 0.60402, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5869 - accuracy: 0.8750 - val_loss: 0.6040 - val_accuracy: 0.7708\n",
      "Epoch 40/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5870 - accuracy: 0.8571\n",
      "Epoch 00040: val_loss improved from 0.60402 to 0.60399, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5867 - accuracy: 0.8750 - val_loss: 0.6040 - val_accuracy: 0.7708\n",
      "Epoch 41/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5786 - accuracy: 0.8605\n",
      "Epoch 00041: val_loss improved from 0.60399 to 0.60376, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5866 - accuracy: 0.8750 - val_loss: 0.6038 - val_accuracy: 0.7708\n",
      "Epoch 42/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5886 - accuracy: 0.9070\n",
      "Epoch 00042: val_loss improved from 0.60376 to 0.60352, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5864 - accuracy: 0.8750 - val_loss: 0.6035 - val_accuracy: 0.7708\n",
      "Epoch 43/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5809 - accuracy: 0.8571\n",
      "Epoch 00043: val_loss did not improve from 0.60352\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 0.5863 - accuracy: 0.8750 - val_loss: 0.6036 - val_accuracy: 0.7708\n",
      "Epoch 44/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5834 - accuracy: 0.8605\n",
      "Epoch 00044: val_loss improved from 0.60352 to 0.60311, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5860 - accuracy: 0.8750 - val_loss: 0.6031 - val_accuracy: 0.8125\n",
      "Epoch 45/100\n",
      "46/48 [===========================>..] - ETA: 0s - loss: 0.5859 - accuracy: 0.8696\n",
      "Epoch 00045: val_loss did not improve from 0.60311\n",
      "48/48 [==============================] - 1s 20ms/sample - loss: 0.5858 - accuracy: 0.8750 - val_loss: 0.6033 - val_accuracy: 0.8125\n",
      "Epoch 46/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5748 - accuracy: 0.8571\n",
      "Epoch 00046: val_loss improved from 0.60311 to 0.60309, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5857 - accuracy: 0.8750 - val_loss: 0.6031 - val_accuracy: 0.8125\n",
      "Epoch 47/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5831 - accuracy: 0.8723\n",
      "Epoch 00047: val_loss improved from 0.60309 to 0.60281, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5856 - accuracy: 0.8750 - val_loss: 0.6028 - val_accuracy: 0.8125\n",
      "Epoch 48/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5773 - accuracy: 0.8605\n",
      "Epoch 00048: val_loss improved from 0.60281 to 0.60261, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5854 - accuracy: 0.8750 - val_loss: 0.6026 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5874 - accuracy: 0.8936\n",
      "Epoch 00049: val_loss improved from 0.60261 to 0.60251, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5852 - accuracy: 0.8750 - val_loss: 0.6025 - val_accuracy: 0.8125\n",
      "Epoch 50/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5850 - accuracy: 0.8810\n",
      "Epoch 00050: val_loss improved from 0.60251 to 0.60218, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5850 - accuracy: 0.8750 - val_loss: 0.6022 - val_accuracy: 0.8125\n",
      "Epoch 51/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5819 - accuracy: 0.8837\n",
      "Epoch 00051: val_loss improved from 0.60218 to 0.60209, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5849 - accuracy: 0.8750 - val_loss: 0.6021 - val_accuracy: 0.8125\n",
      "Epoch 52/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5929 - accuracy: 0.8837\n",
      "Epoch 00052: val_loss improved from 0.60209 to 0.60208, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5848 - accuracy: 0.8750 - val_loss: 0.6021 - val_accuracy: 0.8125\n",
      "Epoch 53/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5765 - accuracy: 0.8837\n",
      "Epoch 00053: val_loss improved from 0.60208 to 0.60190, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5845 - accuracy: 0.8958 - val_loss: 0.6019 - val_accuracy: 0.8125\n",
      "Epoch 54/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5820 - accuracy: 0.8837\n",
      "Epoch 00054: val_loss improved from 0.60190 to 0.60159, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5844 - accuracy: 0.8958 - val_loss: 0.6016 - val_accuracy: 0.8125\n",
      "Epoch 55/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5813 - accuracy: 0.8837\n",
      "Epoch 00055: val_loss improved from 0.60159 to 0.60158, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 22ms/sample - loss: 0.5841 - accuracy: 0.8750 - val_loss: 0.6016 - val_accuracy: 0.8125\n",
      "Epoch 56/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5810 - accuracy: 0.9070\n",
      "Epoch 00056: val_loss did not improve from 0.60158\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 0.5840 - accuracy: 0.8958 - val_loss: 0.6016 - val_accuracy: 0.8125\n",
      "Epoch 57/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5702 - accuracy: 0.8605\n",
      "Epoch 00057: val_loss improved from 0.60158 to 0.60136, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5840 - accuracy: 0.8750 - val_loss: 0.6014 - val_accuracy: 0.8125\n",
      "Epoch 58/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5839 - accuracy: 0.8571\n",
      "Epoch 00058: val_loss improved from 0.60136 to 0.60120, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5837 - accuracy: 0.8750 - val_loss: 0.6012 - val_accuracy: 0.8125\n",
      "Epoch 59/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5861 - accuracy: 0.9362\n",
      "Epoch 00059: val_loss did not improve from 0.60120\n",
      "48/48 [==============================] - 1s 20ms/sample - loss: 0.5835 - accuracy: 0.9375 - val_loss: 0.6012 - val_accuracy: 0.8125\n",
      "Epoch 60/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5837 - accuracy: 0.9048\n",
      "Epoch 00060: val_loss improved from 0.60120 to 0.60105, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5833 - accuracy: 0.9167 - val_loss: 0.6010 - val_accuracy: 0.8125\n",
      "Epoch 61/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5774 - accuracy: 0.9762\n",
      "Epoch 00061: val_loss improved from 0.60105 to 0.60073, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5832 - accuracy: 0.9583 - val_loss: 0.6007 - val_accuracy: 0.8125\n",
      "Epoch 62/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5776 - accuracy: 0.9048\n",
      "Epoch 00062: val_loss improved from 0.60073 to 0.60049, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5830 - accuracy: 0.9167 - val_loss: 0.6005 - val_accuracy: 0.8125\n",
      "Epoch 63/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5942 - accuracy: 0.9524\n",
      "Epoch 00063: val_loss improved from 0.60049 to 0.60037, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5828 - accuracy: 0.9375 - val_loss: 0.6004 - val_accuracy: 0.8125\n",
      "Epoch 64/100\n",
      "46/48 [===========================>..] - ETA: 0s - loss: 0.5872 - accuracy: 0.9783\n",
      "Epoch 00064: val_loss improved from 0.60037 to 0.60007, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5826 - accuracy: 0.9583 - val_loss: 0.6001 - val_accuracy: 0.8125\n",
      "Epoch 65/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5856 - accuracy: 0.9535\n",
      "Epoch 00065: val_loss did not improve from 0.60007\n",
      "48/48 [==============================] - 1s 20ms/sample - loss: 0.5825 - accuracy: 0.9583 - val_loss: 0.6001 - val_accuracy: 0.8125\n",
      "Epoch 66/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5798 - accuracy: 0.9767\n",
      "Epoch 00066: val_loss improved from 0.60007 to 0.59994, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5823 - accuracy: 0.9792 - val_loss: 0.5999 - val_accuracy: 0.8125\n",
      "Epoch 67/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5846 - accuracy: 0.9787\n",
      "Epoch 00067: val_loss improved from 0.59994 to 0.59991, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5821 - accuracy: 0.9792 - val_loss: 0.5999 - val_accuracy: 0.8125\n",
      "Epoch 68/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5707 - accuracy: 0.9762\n",
      "Epoch 00068: val_loss improved from 0.59991 to 0.59971, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5820 - accuracy: 0.9792 - val_loss: 0.5997 - val_accuracy: 0.8125\n",
      "Epoch 69/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5794 - accuracy: 0.9787\n",
      "Epoch 00069: val_loss improved from 0.59971 to 0.59956, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5819 - accuracy: 0.9792 - val_loss: 0.5996 - val_accuracy: 0.8125\n",
      "Epoch 70/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5848 - accuracy: 0.9767\n",
      "Epoch 00070: val_loss improved from 0.59956 to 0.59944, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 22ms/sample - loss: 0.5817 - accuracy: 0.9792 - val_loss: 0.5994 - val_accuracy: 0.8125\n",
      "Epoch 71/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5789 - accuracy: 1.0000\n",
      "Epoch 00071: val_loss improved from 0.59944 to 0.59917, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5815 - accuracy: 1.0000 - val_loss: 0.5992 - val_accuracy: 0.8125\n",
      "Epoch 72/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5836 - accuracy: 1.0000\n",
      "Epoch 00072: val_loss improved from 0.59917 to 0.59911, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5814 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.8125\n",
      "Epoch 73/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5783 - accuracy: 0.9767\n",
      "Epoch 00073: val_loss improved from 0.59911 to 0.59901, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5811 - accuracy: 0.9792 - val_loss: 0.5990 - val_accuracy: 0.8125\n",
      "Epoch 74/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5754 - accuracy: 1.0000\n",
      "Epoch 00074: val_loss did not improve from 0.59901\n",
      "48/48 [==============================] - 1s 20ms/sample - loss: 0.5810 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.8125\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5888 - accuracy: 1.0000\n",
      "Epoch 00075: val_loss improved from 0.59901 to 0.59859, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5808 - accuracy: 1.0000 - val_loss: 0.5986 - val_accuracy: 0.8125\n",
      "Epoch 76/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5810 - accuracy: 1.0000\n",
      "Epoch 00076: val_loss did not improve from 0.59859\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 0.5807 - accuracy: 1.0000 - val_loss: 0.5986 - val_accuracy: 0.8125\n",
      "Epoch 77/100\n",
      "46/48 [===========================>..] - ETA: 0s - loss: 0.5806 - accuracy: 0.9783\n",
      "Epoch 00077: val_loss improved from 0.59859 to 0.59849, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5805 - accuracy: 0.9792 - val_loss: 0.5985 - val_accuracy: 0.8125\n",
      "Epoch 78/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5720 - accuracy: 1.0000\n",
      "Epoch 00078: val_loss improved from 0.59849 to 0.59844, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5803 - accuracy: 1.0000 - val_loss: 0.5984 - val_accuracy: 0.8125\n",
      "Epoch 79/100\n",
      "46/48 [===========================>..] - ETA: 0s - loss: 0.5750 - accuracy: 1.0000\n",
      "Epoch 00079: val_loss improved from 0.59844 to 0.59798, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5802 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.8125\n",
      "Epoch 80/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5970 - accuracy: 1.0000\n",
      "Epoch 00080: val_loss improved from 0.59798 to 0.59782, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5800 - accuracy: 1.0000 - val_loss: 0.5978 - val_accuracy: 0.8125\n",
      "Epoch 81/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5805 - accuracy: 1.0000\n",
      "Epoch 00081: val_loss did not improve from 0.59782\n",
      "48/48 [==============================] - 1s 20ms/sample - loss: 0.5800 - accuracy: 1.0000 - val_loss: 0.5979 - val_accuracy: 0.8125\n",
      "Epoch 82/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5819 - accuracy: 1.0000\n",
      "Epoch 00082: val_loss improved from 0.59782 to 0.59757, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5797 - accuracy: 1.0000 - val_loss: 0.5976 - val_accuracy: 0.8125\n",
      "Epoch 83/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5849 - accuracy: 1.0000\n",
      "Epoch 00083: val_loss improved from 0.59757 to 0.59753, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5796 - accuracy: 1.0000 - val_loss: 0.5975 - val_accuracy: 0.8125\n",
      "Epoch 84/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5738 - accuracy: 1.0000\n",
      "Epoch 00084: val_loss improved from 0.59753 to 0.59744, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5794 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.8125\n",
      "Epoch 85/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5737 - accuracy: 1.0000\n",
      "Epoch 00085: val_loss improved from 0.59744 to 0.59724, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5793 - accuracy: 1.0000 - val_loss: 0.5972 - val_accuracy: 0.8125\n",
      "Epoch 86/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5766 - accuracy: 1.0000\n",
      "Epoch 00086: val_loss improved from 0.59724 to 0.59712, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5791 - accuracy: 1.0000 - val_loss: 0.5971 - val_accuracy: 0.8125\n",
      "Epoch 87/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5756 - accuracy: 1.0000\n",
      "Epoch 00087: val_loss improved from 0.59712 to 0.59702, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5789 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.8125\n",
      "Epoch 88/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5762 - accuracy: 1.0000\n",
      "Epoch 00088: val_loss improved from 0.59702 to 0.59682, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5788 - accuracy: 1.0000 - val_loss: 0.5968 - val_accuracy: 0.8125\n",
      "Epoch 89/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5868 - accuracy: 1.0000\n",
      "Epoch 00089: val_loss did not improve from 0.59682\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 0.5786 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.8125\n",
      "Epoch 90/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5898 - accuracy: 1.0000\n",
      "Epoch 00090: val_loss improved from 0.59682 to 0.59643, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5785 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 0.8125\n",
      "Epoch 91/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5759 - accuracy: 1.0000\n",
      "Epoch 00091: val_loss did not improve from 0.59643\n",
      "48/48 [==============================] - 1s 20ms/sample - loss: 0.5785 - accuracy: 1.0000 - val_loss: 0.5969 - val_accuracy: 0.8125\n",
      "Epoch 92/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5755 - accuracy: 1.0000\n",
      "Epoch 00092: val_loss improved from 0.59643 to 0.59628, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5781 - accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.8125\n",
      "Epoch 93/100\n",
      "47/48 [============================>.] - ETA: 0s - loss: 0.5753 - accuracy: 1.0000\n",
      "Epoch 00093: val_loss improved from 0.59628 to 0.59613, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5780 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5694 - accuracy: 1.0000\n",
      "Epoch 00094: val_loss improved from 0.59613 to 0.59612, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5778 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5805 - accuracy: 1.0000\n",
      "Epoch 00095: val_loss improved from 0.59612 to 0.59571, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5777 - accuracy: 1.0000 - val_loss: 0.5957 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5807 - accuracy: 1.0000\n",
      "Epoch 00096: val_loss improved from 0.59571 to 0.59559, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5775 - accuracy: 1.0000 - val_loss: 0.5956 - val_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5805 - accuracy: 1.0000\n",
      "Epoch 00097: val_loss improved from 0.59559 to 0.59558, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5773 - accuracy: 1.0000 - val_loss: 0.5956 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5745 - accuracy: 1.0000\n",
      "Epoch 00098: val_loss improved from 0.59558 to 0.59552, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5772 - accuracy: 1.0000 - val_loss: 0.5955 - val_accuracy: 0.8542\n",
      "Epoch 99/100\n",
      "42/48 [=========================>....] - ETA: 0s - loss: 0.5829 - accuracy: 1.0000\n",
      "Epoch 00099: val_loss improved from 0.59552 to 0.59543, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5770 - accuracy: 1.0000 - val_loss: 0.5954 - val_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "43/48 [=========================>....] - ETA: 0s - loss: 0.5625 - accuracy: 1.0000\n",
      "Epoch 00100: val_loss improved from 0.59543 to 0.59525, saving model to siamese_network.h5\n",
      "48/48 [==============================] - 1s 21ms/sample - loss: 0.5769 - accuracy: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.8542\n"
     ]
    }
   ],
   "source": [
    "\"\"\" train the model \"\"\"\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "siamese.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# siamese.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "siamese.summary()\n",
    "history = siamese.fit([x_train_1, x_train_2],\n",
    "    labels_train,\n",
    "    validation_data=([x_val_1, x_val_2], labels_val),\n",
    "    batch_size=1,\n",
    "    epochs=100,   # 175 for contrastive 100 for cross ent\n",
    "    callbacks = [checkpointer, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "929bb5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "utils.plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c90ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the cross entropy binary loss\n",
    "utils.plt_metric(history=history.history, metric=\"loss\", title=\"Binary Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3064505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296/1296 [==============================] - 5s 4ms/sample - loss: 0.5855 - accuracy: 0.9151\n",
      "test loss, test acc: [0.5855032544077179, 0.91512346]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Test the model \"\"\"\n",
    "results = siamese.evaluate([x_test_1, x_test_2], labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce353a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1498915 , 0.03659326, 0.57890034, ..., 0.00566136, 0.56869376,\n",
       "       0.01053633], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = siamese.predict([x_test_1, x_test_2]).squeeze()\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36581777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26812783"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a7a1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred = Y_pred > 0.5\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "934e3302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = labels_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3151112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on test data\n",
      "Accuracy: 0.9151234567901234\n",
      "Precision: 0.9274406332453825\n",
      "Recall: 0.9151234567901234\n",
      "ROC AUC: 0.9151234567901234\n",
      "F1: 0.9145075669438855\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluate on test data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2089133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)    \n",
    "# cm_display = ConfusionMatrixDisplay(cm, labels_test).plot()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a10b0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca300cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
