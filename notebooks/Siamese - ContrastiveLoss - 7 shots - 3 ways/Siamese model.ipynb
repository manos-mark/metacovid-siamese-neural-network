{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9bc068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0927a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.1.0\n",
      "\t• tf.keras version: 2.2.4-tf\n",
      "\t• Running on GPU\n"
     ]
    }
   ],
   "source": [
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f60667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 images belonging to 3 classes.\n",
      "The train set contains 21\n",
      "Found 21 images belonging to 3 classes.\n",
      "The valid set contains 21\n",
      "Found 648 images belonging to 3 classes.\n",
      "The test set contains 648\n"
     ]
    }
   ],
   "source": [
    "basedir = os.path.join(\"C:\\\\Users\\\\aktas\\\\Desktop\\\\VIBOT\\\\3.semester\\\\Meta-Learning\\\\project_final\\\\metacovid-siamese-neural-network\", \"dataset\", \"siamese_3w\") \n",
    "\n",
    "train_image_list, train_y_list = utils.load_images(basedir, 'train', (100,100))\n",
    "print(\"The train set contains\",len(train_image_list)) \n",
    "\n",
    "valid_image_list, valid_y_list = utils.load_images(basedir, 'validation', (100,100))   \n",
    "print(\"The valid set contains\", len(valid_image_list))  \n",
    "\n",
    "test_image_list, test_y_list = utils.load_images(basedir, 'test', (100,100))   \n",
    "print(\"The test set contains\", len(test_image_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a873fba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs for training 42\n",
      "number of pairs for validation 42\n",
      "number of pairs for test 1296\n"
     ]
    }
   ],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train = utils.make_pairs(train_image_list, train_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_val, labels_val = utils.make_pairs(valid_image_list, valid_y_list)\n",
    "\n",
    "# make test pairs\n",
    "pairs_test, labels_test = utils.make_pairs(test_image_list, test_y_list)\n",
    "\n",
    "x_train_1 = pairs_train[:, 0]  \n",
    "x_train_2 = pairs_train[:, 1]\n",
    "print(\"number of pairs for training\", np.shape(x_train_1)[0]) \n",
    "\n",
    "x_val_1 = pairs_val[:, 0] \n",
    "x_val_2 = pairs_val[:, 1]\n",
    "print(\"number of pairs for validation\", np.shape(x_val_1)[0]) \n",
    "\n",
    "x_test_1 = pairs_test[:, 0] \n",
    "x_test_2 = pairs_test[:, 1]\n",
    "print(\"number of pairs for test\", np.shape(x_test_1)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9dade0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 5120)         14748995    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "SIAMESE_MODEL_FNAME = 'siamese_network.h5'\n",
    "EMBEDDING_MODEL_FNAME = 'embedding_network.h5'\n",
    "\n",
    "input_1 = Input((100,100,3))\n",
    "input_2 = Input((100,100,3))\n",
    "\n",
    "embedding_network = tf.keras.models.load_model(EMBEDDING_MODEL_FNAME)\n",
    "embedding_network.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential() \n",
    "for layer in embedding_network.layers:  \n",
    "    model.add(layer) \n",
    "\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dense(5120, name='den', activation='sigmoid', kernel_regularizer='l2')) \n",
    " \n",
    "output_1 = model(input_1) \n",
    "output_2 = model(input_2) \n",
    " \n",
    "merge_layer = Lambda(utils.manhattan_distance)([output_1, output_2]) \n",
    "output_layer = Dense(1, activation=\"sigmoid\")(merge_layer) \n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer) \n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8b4a648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" callbacks \"\"\"\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.0001)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='siamese_network.h5', verbose=1, \n",
    "                                save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b21af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 5120)         14748995    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n",
      "Train on 42 samples, validate on 42 samples\n",
      "Epoch 1/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2081 - accuracy: 0.5405\n",
      "Epoch 00001: val_loss improved from inf to 0.26011, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 4s 107ms/sample - loss: 0.2379 - accuracy: 0.5000 - val_loss: 0.2601 - val_accuracy: 0.6429\n",
      "Epoch 2/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.2129 - accuracy: 0.5135\n",
      "Epoch 00002: val_loss improved from 0.26011 to 0.23962, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.2183 - accuracy: 0.5000 - val_loss: 0.2396 - val_accuracy: 0.6429\n",
      "Epoch 3/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1896 - accuracy: 0.5405\n",
      "Epoch 00003: val_loss improved from 0.23962 to 0.22270, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.2014 - accuracy: 0.5238 - val_loss: 0.2227 - val_accuracy: 0.6429\n",
      "Epoch 4/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1881 - accuracy: 0.5405\n",
      "Epoch 00004: val_loss improved from 0.22270 to 0.20731, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1868 - accuracy: 0.5238 - val_loss: 0.2073 - val_accuracy: 0.6429\n",
      "Epoch 5/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1797 - accuracy: 0.5833\n",
      "Epoch 00005: val_loss improved from 0.20731 to 0.19407, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1743 - accuracy: 0.5952 - val_loss: 0.1941 - val_accuracy: 0.6667\n",
      "Epoch 6/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1449 - accuracy: 0.6486\n",
      "Epoch 00006: val_loss improved from 0.19407 to 0.18478, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1624 - accuracy: 0.6429 - val_loss: 0.1848 - val_accuracy: 0.6905\n",
      "Epoch 7/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1595 - accuracy: 0.6757\n",
      "Epoch 00007: val_loss improved from 0.18478 to 0.17461, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1537 - accuracy: 0.6905 - val_loss: 0.1746 - val_accuracy: 0.7143\n",
      "Epoch 8/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1451 - accuracy: 0.7838\n",
      "Epoch 00008: val_loss improved from 0.17461 to 0.16409, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1465 - accuracy: 0.8095 - val_loss: 0.1641 - val_accuracy: 0.7381\n",
      "Epoch 9/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1433 - accuracy: 0.8378\n",
      "Epoch 00009: val_loss improved from 0.16409 to 0.15759, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1405 - accuracy: 0.8333 - val_loss: 0.1576 - val_accuracy: 0.7381\n",
      "Epoch 10/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1394 - accuracy: 0.8919\n",
      "Epoch 00010: val_loss improved from 0.15759 to 0.15323, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1376 - accuracy: 0.8571 - val_loss: 0.1532 - val_accuracy: 0.8333\n",
      "Epoch 11/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1388 - accuracy: 0.8780\n",
      "Epoch 00011: val_loss improved from 0.15323 to 0.15071, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1356 - accuracy: 0.8810 - val_loss: 0.1507 - val_accuracy: 0.8333\n",
      "Epoch 12/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1387 - accuracy: 0.8649\n",
      "Epoch 00012: val_loss improved from 0.15071 to 0.14900, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1346 - accuracy: 0.8810 - val_loss: 0.1490 - val_accuracy: 0.8333\n",
      "Epoch 13/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1209 - accuracy: 0.8611\n",
      "Epoch 00013: val_loss did not improve from 0.14900\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1332 - accuracy: 0.8810 - val_loss: 0.1497 - val_accuracy: 0.8333\n",
      "Epoch 14/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1430 - accuracy: 0.8649\n",
      "Epoch 00014: val_loss improved from 0.14900 to 0.14735, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1326 - accuracy: 0.8810 - val_loss: 0.1473 - val_accuracy: 0.8333\n",
      "Epoch 15/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1324 - accuracy: 0.8611\n",
      "Epoch 00015: val_loss did not improve from 0.14735\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1314 - accuracy: 0.8810 - val_loss: 0.1487 - val_accuracy: 0.8333\n",
      "Epoch 16/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1287 - accuracy: 0.8649\n",
      "Epoch 00016: val_loss improved from 0.14735 to 0.14708, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1311 - accuracy: 0.8810 - val_loss: 0.1471 - val_accuracy: 0.8333\n",
      "Epoch 17/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1382 - accuracy: 0.8611\n",
      "Epoch 00017: val_loss improved from 0.14708 to 0.14623, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1304 - accuracy: 0.8810 - val_loss: 0.1462 - val_accuracy: 0.8333\n",
      "Epoch 18/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1334 - accuracy: 0.8649\n",
      "Epoch 00018: val_loss improved from 0.14623 to 0.14452, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1296 - accuracy: 0.8810 - val_loss: 0.1445 - val_accuracy: 0.8333\n",
      "Epoch 19/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1211 - accuracy: 0.8649\n",
      "Epoch 00019: val_loss improved from 0.14452 to 0.14416, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1297 - accuracy: 0.8810 - val_loss: 0.1442 - val_accuracy: 0.8333\n",
      "Epoch 20/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1319 - accuracy: 0.8780\n",
      "Epoch 00020: val_loss did not improve from 0.14416\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1289 - accuracy: 0.8810 - val_loss: 0.1456 - val_accuracy: 0.8333\n",
      "Epoch 21/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1310 - accuracy: 0.8919\n",
      "Epoch 00021: val_loss improved from 0.14416 to 0.14277, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1280 - accuracy: 0.8810 - val_loss: 0.1428 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1313 - accuracy: 0.8919\n",
      "Epoch 00022: val_loss did not improve from 0.14277\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1273 - accuracy: 0.9048 - val_loss: 0.1435 - val_accuracy: 0.8333\n",
      "Epoch 23/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1371 - accuracy: 0.8919\n",
      "Epoch 00023: val_loss improved from 0.14277 to 0.14216, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1269 - accuracy: 0.9048 - val_loss: 0.1422 - val_accuracy: 0.8333\n",
      "Epoch 24/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1242 - accuracy: 0.9024\n",
      "Epoch 00024: val_loss did not improve from 0.14216\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1269 - accuracy: 0.9048 - val_loss: 0.1422 - val_accuracy: 0.8571\n",
      "Epoch 25/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1213 - accuracy: 0.9189\n",
      "Epoch 00025: val_loss did not improve from 0.14216\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1264 - accuracy: 0.9048 - val_loss: 0.1444 - val_accuracy: 0.8333\n",
      "Epoch 26/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1178 - accuracy: 0.9250\n",
      "Epoch 00026: val_loss did not improve from 0.14216\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1257 - accuracy: 0.9048 - val_loss: 0.1423 - val_accuracy: 0.8333\n",
      "Epoch 27/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1230 - accuracy: 0.9024\n",
      "Epoch 00027: val_loss did not improve from 0.14216\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1258 - accuracy: 0.9048 - val_loss: 0.1442 - val_accuracy: 0.8333\n",
      "Epoch 28/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1301 - accuracy: 0.8919\n",
      "Epoch 00028: val_loss improved from 0.14216 to 0.14057, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1262 - accuracy: 0.9048 - val_loss: 0.1406 - val_accuracy: 0.8571\n",
      "Epoch 29/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1243 - accuracy: 0.9167\n",
      "Epoch 00029: val_loss did not improve from 0.14057\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1244 - accuracy: 0.9048 - val_loss: 0.1423 - val_accuracy: 0.8333\n",
      "Epoch 30/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1275 - accuracy: 0.9189\n",
      "Epoch 00030: val_loss improved from 0.14057 to 0.13919, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1247 - accuracy: 0.9048 - val_loss: 0.1392 - val_accuracy: 0.8571\n",
      "Epoch 31/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1182 - accuracy: 0.9000\n",
      "Epoch 00031: val_loss did not improve from 0.13919\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1235 - accuracy: 0.9048 - val_loss: 0.1407 - val_accuracy: 0.8571\n",
      "Epoch 32/175\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1177 - accuracy: 0.8947\n",
      "Epoch 00032: val_loss improved from 0.13919 to 0.13891, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1234 - accuracy: 0.9048 - val_loss: 0.1389 - val_accuracy: 0.8571\n",
      "Epoch 33/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1359 - accuracy: 0.8889\n",
      "Epoch 00033: val_loss improved from 0.13891 to 0.13839, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1224 - accuracy: 0.9048 - val_loss: 0.1384 - val_accuracy: 0.8571\n",
      "Epoch 34/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1261 - accuracy: 0.8919\n",
      "Epoch 00034: val_loss did not improve from 0.13839\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1224 - accuracy: 0.9048 - val_loss: 0.1391 - val_accuracy: 0.8571\n",
      "Epoch 35/175\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1224 - accuracy: 0.8947\n",
      "Epoch 00035: val_loss improved from 0.13839 to 0.13706, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 23ms/sample - loss: 0.1220 - accuracy: 0.9048 - val_loss: 0.1371 - val_accuracy: 0.8810\n",
      "Epoch 36/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1095 - accuracy: 0.8889\n",
      "Epoch 00036: val_loss improved from 0.13706 to 0.13666, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1216 - accuracy: 0.9048 - val_loss: 0.1367 - val_accuracy: 0.8810\n",
      "Epoch 37/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1269 - accuracy: 0.9000\n",
      "Epoch 00037: val_loss did not improve from 0.13666\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1209 - accuracy: 0.9048 - val_loss: 0.1373 - val_accuracy: 0.8571\n",
      "Epoch 38/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.9024\n",
      "Epoch 00038: val_loss did not improve from 0.13666\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1205 - accuracy: 0.9048 - val_loss: 0.1387 - val_accuracy: 0.8571\n",
      "Epoch 39/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1201 - accuracy: 0.9250\n",
      "Epoch 00039: val_loss improved from 0.13666 to 0.13630, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 23ms/sample - loss: 0.1206 - accuracy: 0.9048 - val_loss: 0.1363 - val_accuracy: 0.8810\n",
      "Epoch 40/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9024\n",
      "Epoch 00040: val_loss did not improve from 0.13630\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1195 - accuracy: 0.9048 - val_loss: 0.1387 - val_accuracy: 0.8571\n",
      "Epoch 41/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1167 - accuracy: 0.9268\n",
      "Epoch 00041: val_loss improved from 0.13630 to 0.13582, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1202 - accuracy: 0.9048 - val_loss: 0.1358 - val_accuracy: 0.8810\n",
      "Epoch 42/175\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1171 - accuracy: 0.8974\n",
      "Epoch 00042: val_loss improved from 0.13582 to 0.13450, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1194 - accuracy: 0.9048 - val_loss: 0.1345 - val_accuracy: 0.8571\n",
      "Epoch 43/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9024\n",
      "Epoch 00043: val_loss improved from 0.13450 to 0.13422, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1198 - accuracy: 0.9048 - val_loss: 0.1342 - val_accuracy: 0.8571\n",
      "Epoch 44/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1210 - accuracy: 0.9189\n",
      "Epoch 00044: val_loss did not improve from 0.13422\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1182 - accuracy: 0.9048 - val_loss: 0.1371 - val_accuracy: 0.8571\n",
      "Epoch 45/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 0.9024\n",
      "Epoch 00045: val_loss improved from 0.13422 to 0.13396, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1187 - accuracy: 0.9048 - val_loss: 0.1340 - val_accuracy: 0.8571\n",
      "Epoch 46/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1158 - accuracy: 0.9250\n",
      "Epoch 00046: val_loss did not improve from 0.13396\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1179 - accuracy: 0.9048 - val_loss: 0.1352 - val_accuracy: 0.8810\n",
      "Epoch 47/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1266 - accuracy: 0.8919\n",
      "Epoch 00047: val_loss improved from 0.13396 to 0.13309, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1171 - accuracy: 0.9048 - val_loss: 0.1331 - val_accuracy: 0.8571\n",
      "Epoch 48/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9268\n",
      "Epoch 00048: val_loss improved from 0.13309 to 0.13293, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1171 - accuracy: 0.9286 - val_loss: 0.1329 - val_accuracy: 0.8571\n",
      "Epoch 49/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1090 - accuracy: 0.8919\n",
      "Epoch 00049: val_loss did not improve from 0.13293\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1169 - accuracy: 0.9048 - val_loss: 0.1349 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1029 - accuracy: 0.9189\n",
      "Epoch 00050: val_loss did not improve from 0.13293\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1169 - accuracy: 0.9286 - val_loss: 0.1332 - val_accuracy: 0.8571\n",
      "Epoch 51/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1163 - accuracy: 0.9000\n",
      "Epoch 00051: val_loss improved from 0.13293 to 0.13212, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1160 - accuracy: 0.9048 - val_loss: 0.1321 - val_accuracy: 0.8571\n",
      "Epoch 52/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1097 - accuracy: 0.9250\n",
      "Epoch 00052: val_loss improved from 0.13212 to 0.13210, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1157 - accuracy: 0.9048 - val_loss: 0.1321 - val_accuracy: 0.8571\n",
      "Epoch 53/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1189 - accuracy: 0.9189\n",
      "Epoch 00053: val_loss did not improve from 0.13210\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1152 - accuracy: 0.9286 - val_loss: 0.1333 - val_accuracy: 0.8571\n",
      "Epoch 54/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9024\n",
      "Epoch 00054: val_loss did not improve from 0.13210\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1155 - accuracy: 0.9048 - val_loss: 0.1324 - val_accuracy: 0.8571\n",
      "Epoch 55/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1206 - accuracy: 0.9250\n",
      "Epoch 00055: val_loss improved from 0.13210 to 0.13077, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1150 - accuracy: 0.9286 - val_loss: 0.1308 - val_accuracy: 0.8571\n",
      "Epoch 56/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 0.9268\n",
      "Epoch 00056: val_loss improved from 0.13077 to 0.13006, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1153 - accuracy: 0.9286 - val_loss: 0.1301 - val_accuracy: 0.8571\n",
      "Epoch 57/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1122 - accuracy: 0.8919\n",
      "Epoch 00057: val_loss did not improve from 0.13006\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1142 - accuracy: 0.9048 - val_loss: 0.1301 - val_accuracy: 0.8571\n",
      "Epoch 58/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1136 - accuracy: 0.9250\n",
      "Epoch 00058: val_loss did not improve from 0.13006\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1134 - accuracy: 0.9286 - val_loss: 0.1322 - val_accuracy: 0.8571\n",
      "Epoch 59/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1171 - accuracy: 0.9459\n",
      "Epoch 00059: val_loss improved from 0.13006 to 0.12964, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1135 - accuracy: 0.9524 - val_loss: 0.1296 - val_accuracy: 0.8571\n",
      "Epoch 60/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1239 - accuracy: 0.9459\n",
      "Epoch 00060: val_loss did not improve from 0.12964\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1142 - accuracy: 0.9524 - val_loss: 0.1318 - val_accuracy: 0.8571\n",
      "Epoch 61/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1080 - accuracy: 0.9444\n",
      "Epoch 00061: val_loss did not improve from 0.12964\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1128 - accuracy: 0.9524 - val_loss: 0.1297 - val_accuracy: 0.8571\n",
      "Epoch 62/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1048 - accuracy: 0.9459\n",
      "Epoch 00062: val_loss improved from 0.12964 to 0.12853, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1124 - accuracy: 0.9524 - val_loss: 0.1285 - val_accuracy: 0.8810\n",
      "Epoch 63/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1183 - accuracy: 0.9500\n",
      "Epoch 00063: val_loss improved from 0.12853 to 0.12843, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1128 - accuracy: 0.9524 - val_loss: 0.1284 - val_accuracy: 0.8571\n",
      "Epoch 64/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1080 - accuracy: 0.9730\n",
      "Epoch 00064: val_loss improved from 0.12843 to 0.12838, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1124 - accuracy: 0.9524 - val_loss: 0.1284 - val_accuracy: 0.8571\n",
      "Epoch 65/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1003 - accuracy: 0.9444\n",
      "Epoch 00065: val_loss improved from 0.12838 to 0.12771, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1118 - accuracy: 0.9524 - val_loss: 0.1277 - val_accuracy: 0.8810\n",
      "Epoch 66/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1033 - accuracy: 0.9459\n",
      "Epoch 00066: val_loss did not improve from 0.12771\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1108 - accuracy: 0.9524 - val_loss: 0.1297 - val_accuracy: 0.8571\n",
      "Epoch 67/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1064 - accuracy: 0.9500\n",
      "Epoch 00067: val_loss improved from 0.12771 to 0.12739, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1111 - accuracy: 0.9524 - val_loss: 0.1274 - val_accuracy: 0.8571\n",
      "Epoch 68/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1087 - accuracy: 0.9459\n",
      "Epoch 00068: val_loss improved from 0.12739 to 0.12688, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1106 - accuracy: 0.9524 - val_loss: 0.1269 - val_accuracy: 0.8810\n",
      "Epoch 69/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1117 - accuracy: 0.9730\n",
      "Epoch 00069: val_loss did not improve from 0.12688\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1106 - accuracy: 0.9524 - val_loss: 0.1276 - val_accuracy: 0.8571\n",
      "Epoch 70/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1095 - accuracy: 0.9444\n",
      "Epoch 00070: val_loss improved from 0.12688 to 0.12610, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1104 - accuracy: 0.9524 - val_loss: 0.1261 - val_accuracy: 0.8810\n",
      "Epoch 71/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1080 - accuracy: 0.9459\n",
      "Epoch 00071: val_loss did not improve from 0.12610\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1098 - accuracy: 0.9524 - val_loss: 0.1274 - val_accuracy: 0.8571\n",
      "Epoch 72/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1168 - accuracy: 0.9444\n",
      "Epoch 00072: val_loss did not improve from 0.12610\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1100 - accuracy: 0.9524 - val_loss: 0.1276 - val_accuracy: 0.8571\n",
      "Epoch 73/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1035 - accuracy: 0.9444\n",
      "Epoch 00073: val_loss improved from 0.12610 to 0.12550, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1090 - accuracy: 0.9524 - val_loss: 0.1255 - val_accuracy: 0.8810\n",
      "Epoch 74/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1077 - accuracy: 0.9722\n",
      "Epoch 00074: val_loss did not improve from 0.12550\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1092 - accuracy: 0.9524 - val_loss: 0.1259 - val_accuracy: 0.8810\n",
      "Epoch 75/175\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.1104 - accuracy: 0.9487\n",
      "Epoch 00075: val_loss did not improve from 0.12550\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1084 - accuracy: 0.9524 - val_loss: 0.1257 - val_accuracy: 0.8810\n",
      "Epoch 76/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0978 - accuracy: 0.9730\n",
      "Epoch 00076: val_loss improved from 0.12550 to 0.12459, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1083 - accuracy: 0.9524 - val_loss: 0.1246 - val_accuracy: 0.8810\n",
      "Epoch 77/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0983 - accuracy: 0.9730\n",
      "Epoch 00077: val_loss did not improve from 0.12459\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1076 - accuracy: 0.9524 - val_loss: 0.1250 - val_accuracy: 0.8810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1161 - accuracy: 0.9459\n",
      "Epoch 00078: val_loss did not improve from 0.12459\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1072 - accuracy: 0.9524 - val_loss: 0.1267 - val_accuracy: 0.8571\n",
      "Epoch 79/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1097 - accuracy: 0.9512\n",
      "Epoch 00079: val_loss improved from 0.12459 to 0.12352, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1072 - accuracy: 0.9524 - val_loss: 0.1235 - val_accuracy: 0.9048\n",
      "Epoch 80/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0970 - accuracy: 0.9730\n",
      "Epoch 00080: val_loss did not improve from 0.12352\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1069 - accuracy: 0.9524 - val_loss: 0.1237 - val_accuracy: 0.8810\n",
      "Epoch 81/175\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.1068 - accuracy: 0.9474\n",
      "Epoch 00081: val_loss did not improve from 0.12352\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1062 - accuracy: 0.9524 - val_loss: 0.1246 - val_accuracy: 0.9048\n",
      "Epoch 82/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0992 - accuracy: 0.9459\n",
      "Epoch 00082: val_loss improved from 0.12352 to 0.12264, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1063 - accuracy: 0.9524 - val_loss: 0.1226 - val_accuracy: 0.9048\n",
      "Epoch 83/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9512\n",
      "Epoch 00083: val_loss did not improve from 0.12264\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1061 - accuracy: 0.9524 - val_loss: 0.1241 - val_accuracy: 0.9048\n",
      "Epoch 84/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1089 - accuracy: 0.9459\n",
      "Epoch 00084: val_loss improved from 0.12264 to 0.12246, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1055 - accuracy: 0.9524 - val_loss: 0.1225 - val_accuracy: 0.9048\n",
      "Epoch 85/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.9512\n",
      "Epoch 00085: val_loss improved from 0.12246 to 0.12226, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1054 - accuracy: 0.9524 - val_loss: 0.1223 - val_accuracy: 0.9048\n",
      "Epoch 86/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0977 - accuracy: 0.9459\n",
      "Epoch 00086: val_loss improved from 0.12226 to 0.12185, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1047 - accuracy: 0.9524 - val_loss: 0.1219 - val_accuracy: 0.9048\n",
      "Epoch 87/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1071 - accuracy: 0.9512\n",
      "Epoch 00087: val_loss improved from 0.12185 to 0.12180, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1046 - accuracy: 0.9524 - val_loss: 0.1218 - val_accuracy: 0.9048\n",
      "Epoch 88/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1104 - accuracy: 0.9444\n",
      "Epoch 00088: val_loss did not improve from 0.12180\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1049 - accuracy: 0.9524 - val_loss: 0.1260 - val_accuracy: 0.8571\n",
      "Epoch 89/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1022 - accuracy: 0.9459\n",
      "Epoch 00089: val_loss did not improve from 0.12180\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1051 - accuracy: 0.9524 - val_loss: 0.1223 - val_accuracy: 0.9048\n",
      "Epoch 90/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9512\n",
      "Epoch 00090: val_loss improved from 0.12180 to 0.12118, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1034 - accuracy: 0.9524 - val_loss: 0.1212 - val_accuracy: 0.9048\n",
      "Epoch 91/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9512\n",
      "Epoch 00091: val_loss improved from 0.12118 to 0.12026, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1033 - accuracy: 0.9524 - val_loss: 0.1203 - val_accuracy: 0.9048\n",
      "Epoch 92/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1011 - accuracy: 0.9512\n",
      "Epoch 00092: val_loss did not improve from 0.12026\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1032 - accuracy: 0.9524 - val_loss: 0.1214 - val_accuracy: 0.9048\n",
      "Epoch 93/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.1043 - accuracy: 0.9444\n",
      "Epoch 00093: val_loss did not improve from 0.12026\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1031 - accuracy: 0.9524 - val_loss: 0.1219 - val_accuracy: 0.9048\n",
      "Epoch 94/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0951 - accuracy: 0.9459\n",
      "Epoch 00094: val_loss did not improve from 0.12026\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1028 - accuracy: 0.9524 - val_loss: 0.1210 - val_accuracy: 0.9048\n",
      "Epoch 95/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0981 - accuracy: 0.9730\n",
      "Epoch 00095: val_loss improved from 0.12026 to 0.11928, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1018 - accuracy: 0.9524 - val_loss: 0.1193 - val_accuracy: 0.9048\n",
      "Epoch 96/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1027 - accuracy: 0.9500\n",
      "Epoch 00096: val_loss improved from 0.11928 to 0.11867, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1023 - accuracy: 0.9524 - val_loss: 0.1187 - val_accuracy: 0.9048\n",
      "Epoch 97/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1052 - accuracy: 0.9459\n",
      "Epoch 00097: val_loss improved from 0.11867 to 0.11826, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1017 - accuracy: 0.9524 - val_loss: 0.1183 - val_accuracy: 0.9048\n",
      "Epoch 98/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1001 - accuracy: 0.9459\n",
      "Epoch 00098: val_loss did not improve from 0.11826\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.1016 - accuracy: 0.9524 - val_loss: 0.1188 - val_accuracy: 0.9048\n",
      "Epoch 99/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.1058 - accuracy: 0.9500\n",
      "Epoch 00099: val_loss improved from 0.11826 to 0.11808, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.1008 - accuracy: 0.9524 - val_loss: 0.1181 - val_accuracy: 0.9048\n",
      "Epoch 100/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0983 - accuracy: 0.9756\n",
      "Epoch 00100: val_loss did not improve from 0.11808\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1004 - accuracy: 0.9762 - val_loss: 0.1212 - val_accuracy: 0.9048\n",
      "Epoch 101/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0967 - accuracy: 0.9500\n",
      "Epoch 00101: val_loss improved from 0.11808 to 0.11778, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.1009 - accuracy: 0.9524 - val_loss: 0.1178 - val_accuracy: 0.9048\n",
      "Epoch 102/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0925 - accuracy: 0.9750\n",
      "Epoch 00102: val_loss did not improve from 0.11778\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.1001 - accuracy: 0.9524 - val_loss: 0.1187 - val_accuracy: 0.9048\n",
      "Epoch 103/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0978 - accuracy: 0.9459\n",
      "Epoch 00103: val_loss improved from 0.11778 to 0.11719, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0996 - accuracy: 0.9524 - val_loss: 0.1172 - val_accuracy: 0.9048\n",
      "Epoch 104/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0999 - accuracy: 0.9500\n",
      "Epoch 00104: val_loss improved from 0.11719 to 0.11652, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0997 - accuracy: 0.9524 - val_loss: 0.1165 - val_accuracy: 0.9048\n",
      "Epoch 105/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0925 - accuracy: 0.9730\n",
      "Epoch 00105: val_loss did not improve from 0.11652\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0991 - accuracy: 0.9762 - val_loss: 0.1170 - val_accuracy: 0.9048\n",
      "Epoch 106/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0970 - accuracy: 0.9459\n",
      "Epoch 00106: val_loss did not improve from 0.11652\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0987 - accuracy: 0.9524 - val_loss: 0.1174 - val_accuracy: 0.9048\n",
      "Epoch 107/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.1010 - accuracy: 0.9512\n",
      "Epoch 00107: val_loss improved from 0.11652 to 0.11567, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0987 - accuracy: 0.9524 - val_loss: 0.1157 - val_accuracy: 0.9524\n",
      "Epoch 108/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9512\n",
      "Epoch 00108: val_loss did not improve from 0.11567\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0986 - accuracy: 0.9524 - val_loss: 0.1163 - val_accuracy: 0.9524\n",
      "Epoch 109/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0939 - accuracy: 0.9750\n",
      "Epoch 00109: val_loss did not improve from 0.11567\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0981 - accuracy: 0.9762 - val_loss: 0.1167 - val_accuracy: 0.9524\n",
      "Epoch 110/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1005 - accuracy: 0.9459\n",
      "Epoch 00110: val_loss improved from 0.11567 to 0.11530, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0976 - accuracy: 0.9524 - val_loss: 0.1153 - val_accuracy: 0.9048\n",
      "Epoch 111/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0952 - accuracy: 1.0000\n",
      "Epoch 00111: val_loss did not improve from 0.11530\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9524\n",
      "Epoch 112/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0954 - accuracy: 0.9512\n",
      "Epoch 00112: val_loss improved from 0.11530 to 0.11474, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0976 - accuracy: 0.9524 - val_loss: 0.1147 - val_accuracy: 0.9524\n",
      "Epoch 113/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 0.9756\n",
      "Epoch 00113: val_loss improved from 0.11474 to 0.11440, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0966 - accuracy: 0.9762 - val_loss: 0.1144 - val_accuracy: 0.9524\n",
      "Epoch 114/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0999 - accuracy: 0.9730\n",
      "Epoch 00114: val_loss did not improve from 0.11440\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0966 - accuracy: 0.9762 - val_loss: 0.1170 - val_accuracy: 0.9524\n",
      "Epoch 115/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0951 - accuracy: 0.9459\n",
      "Epoch 00115: val_loss did not improve from 0.11440\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0966 - accuracy: 0.9524 - val_loss: 0.1144 - val_accuracy: 0.9048\n",
      "Epoch 116/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0962 - accuracy: 0.9500\n",
      "Epoch 00116: val_loss improved from 0.11440 to 0.11353, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0959 - accuracy: 0.9524 - val_loss: 0.1135 - val_accuracy: 0.9524\n",
      "Epoch 117/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0990 - accuracy: 1.0000\n",
      "Epoch 00117: val_loss did not improve from 0.11353\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9524\n",
      "Epoch 118/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0876 - accuracy: 0.9444\n",
      "Epoch 00118: val_loss improved from 0.11353 to 0.11319, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0963 - accuracy: 0.9524 - val_loss: 0.1132 - val_accuracy: 0.9524\n",
      "Epoch 119/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0960 - accuracy: 0.9730\n",
      "Epoch 00119: val_loss did not improve from 0.11319\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0951 - accuracy: 0.9524 - val_loss: 0.1134 - val_accuracy: 0.9524\n",
      "Epoch 120/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0955 - accuracy: 0.9444\n",
      "Epoch 00120: val_loss improved from 0.11319 to 0.11242, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0946 - accuracy: 0.9524 - val_loss: 0.1124 - val_accuracy: 0.9524\n",
      "Epoch 121/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 0.9512\n",
      "Epoch 00121: val_loss did not improve from 0.11242\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0943 - accuracy: 0.9524 - val_loss: 0.1125 - val_accuracy: 0.9524\n",
      "Epoch 122/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.1069 - accuracy: 0.9730\n",
      "Epoch 00122: val_loss did not improve from 0.11242\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0944 - accuracy: 0.9762 - val_loss: 0.1137 - val_accuracy: 0.9524\n",
      "Epoch 123/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9512\n",
      "Epoch 00123: val_loss improved from 0.11242 to 0.11195, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0939 - accuracy: 0.9524 - val_loss: 0.1119 - val_accuracy: 0.9524\n",
      "Epoch 124/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0914 - accuracy: 1.0000\n",
      "Epoch 00124: val_loss improved from 0.11195 to 0.11164, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9524\n",
      "Epoch 125/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0846 - accuracy: 0.9722\n",
      "Epoch 00125: val_loss improved from 0.11164 to 0.11081, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0931 - accuracy: 0.9762 - val_loss: 0.1108 - val_accuracy: 0.9524\n",
      "Epoch 126/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0915 - accuracy: 0.9756\n",
      "Epoch 00126: val_loss did not improve from 0.11081\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0933 - accuracy: 0.9762 - val_loss: 0.1117 - val_accuracy: 0.9524\n",
      "Epoch 127/175\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.0952 - accuracy: 0.9487\n",
      "Epoch 00127: val_loss improved from 0.11081 to 0.11022, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0929 - accuracy: 0.9524 - val_loss: 0.1102 - val_accuracy: 0.9524\n",
      "Epoch 128/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0865 - accuracy: 1.0000\n",
      "Epoch 00128: val_loss did not improve from 0.11022\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0926 - accuracy: 0.9762 - val_loss: 0.1108 - val_accuracy: 0.9524\n",
      "Epoch 129/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0802 - accuracy: 1.0000\n",
      "Epoch 00129: val_loss did not improve from 0.11022\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0924 - accuracy: 0.9762 - val_loss: 0.1115 - val_accuracy: 0.9524\n",
      "Epoch 130/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0945 - accuracy: 1.0000\n",
      "Epoch 00130: val_loss improved from 0.11022 to 0.10965, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0918 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9524\n",
      "Epoch 131/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0893 - accuracy: 1.0000 ETA: 0s - loss: 0.0729 - accuracy\n",
      "Epoch 00131: val_loss did not improve from 0.10965\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0916 - accuracy: 0.9762 - val_loss: 0.1109 - val_accuracy: 0.9524\n",
      "Epoch 132/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0892 - accuracy: 1.0000\n",
      "Epoch 00132: val_loss did not improve from 0.10965\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0912 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0890 - accuracy: 1.0000\n",
      "Epoch 00133: val_loss did not improve from 0.10965\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9524\n",
      "Epoch 134/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0849 - accuracy: 0.9722\n",
      "Epoch 00134: val_loss improved from 0.10965 to 0.10917, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0912 - accuracy: 0.9524 - val_loss: 0.1092 - val_accuracy: 0.9524\n",
      "Epoch 135/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0946 - accuracy: 1.0000\n",
      "Epoch 00135: val_loss improved from 0.10917 to 0.10901, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0903 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9524\n",
      "Epoch 136/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0983 - accuracy: 0.9459\n",
      "Epoch 00136: val_loss improved from 0.10901 to 0.10808, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0907 - accuracy: 0.9524 - val_loss: 0.1081 - val_accuracy: 0.9524\n",
      "Epoch 137/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0873 - accuracy: 1.0000\n",
      "Epoch 00137: val_loss did not improve from 0.10808\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0899 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9524\n",
      "Epoch 138/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0878 - accuracy: 1.0000\n",
      "Epoch 00138: val_loss did not improve from 0.10808\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9524\n",
      "Epoch 139/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0966 - accuracy: 0.9730\n",
      "Epoch 00139: val_loss improved from 0.10808 to 0.10742, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0895 - accuracy: 0.9762 - val_loss: 0.1074 - val_accuracy: 0.9524\n",
      "Epoch 140/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0850 - accuracy: 0.9722\n",
      "Epoch 00140: val_loss did not improve from 0.10742\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0893 - accuracy: 0.9762 - val_loss: 0.1086 - val_accuracy: 0.9524\n",
      "Epoch 141/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0863 - accuracy: 1.0000\n",
      "Epoch 00141: val_loss improved from 0.10742 to 0.10697, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9524\n",
      "Epoch 142/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0863 - accuracy: 1.0000\n",
      "Epoch 00142: val_loss did not improve from 0.10697\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9524\n",
      "Epoch 143/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0868 - accuracy: 0.9730\n",
      "Epoch 00143: val_loss improved from 0.10697 to 0.10615, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0884 - accuracy: 0.9762 - val_loss: 0.1062 - val_accuracy: 0.9524\n",
      "Epoch 144/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0863 - accuracy: 1.0000\n",
      "Epoch 00144: val_loss did not improve from 0.10615\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0883 - accuracy: 0.9762 - val_loss: 0.1074 - val_accuracy: 0.9524\n",
      "Epoch 145/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0879 - accuracy: 1.0000\n",
      "Epoch 00145: val_loss did not improve from 0.10615\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0876 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9524\n",
      "Epoch 146/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9512\n",
      "Epoch 00146: val_loss improved from 0.10615 to 0.10595, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0880 - accuracy: 0.9524 - val_loss: 0.1060 - val_accuracy: 0.9524\n",
      "Epoch 147/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0854 - accuracy: 1.0000\n",
      "Epoch 00147: val_loss did not improve from 0.10595\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9524\n",
      "Epoch 148/175\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.0877 - accuracy: 1.0000\n",
      "Epoch 00148: val_loss did not improve from 0.10595\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0870 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9524\n",
      "Epoch 149/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0888 - accuracy: 1.0000\n",
      "Epoch 00149: val_loss improved from 0.10595 to 0.10468, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9524\n",
      "Epoch 150/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0896 - accuracy: 1.0000\n",
      "Epoch 00150: val_loss did not improve from 0.10468\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9524\n",
      "Epoch 151/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0838 - accuracy: 1.0000\n",
      "Epoch 00151: val_loss did not improve from 0.10468\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0864 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9524\n",
      "Epoch 152/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0878 - accuracy: 1.0000\n",
      "Epoch 00152: val_loss improved from 0.10468 to 0.10435, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9524\n",
      "Epoch 153/175\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.0881 - accuracy: 1.0000\n",
      "Epoch 00153: val_loss did not improve from 0.10435\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9524\n",
      "Epoch 154/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0818 - accuracy: 0.9750\n",
      "Epoch 00154: val_loss did not improve from 0.10435\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0857 - accuracy: 0.9762 - val_loss: 0.1051 - val_accuracy: 0.9524\n",
      "Epoch 155/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0778 - accuracy: 1.0000\n",
      "Epoch 00155: val_loss did not improve from 0.10435\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0851 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9524\n",
      "Epoch 156/175\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.0847 - accuracy: 1.0000\n",
      "Epoch 00156: val_loss improved from 0.10435 to 0.10388, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9524\n",
      "Epoch 157/175\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.0886 - accuracy: 1.0000\n",
      "Epoch 00157: val_loss improved from 0.10388 to 0.10294, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9524\n",
      "Epoch 158/175\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.0829 - accuracy: 1.0000\n",
      "Epoch 00158: val_loss did not improve from 0.10294\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9524\n",
      "Epoch 159/175\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.0828 - accuracy: 1.0000\n",
      "Epoch 00159: val_loss did not improve from 0.10294\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9524\n",
      "Epoch 160/175\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.0847 - accuracy: 1.0000\n",
      "Epoch 00160: val_loss did not improve from 0.10294\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0820 - accuracy: 1.0000\n",
      "Epoch 00161: val_loss improved from 0.10294 to 0.10178, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9524\n",
      "Epoch 162/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0848 - accuracy: 1.0000\n",
      "Epoch 00162: val_loss did not improve from 0.10178\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9524\n",
      "Epoch 163/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0841 - accuracy: 1.0000\n",
      "Epoch 00163: val_loss improved from 0.10178 to 0.10173, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0832 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9524\n",
      "Epoch 164/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0836 - accuracy: 1.0000\n",
      "Epoch 00164: val_loss improved from 0.10173 to 0.10116, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9524\n",
      "Epoch 165/175\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.0846 - accuracy: 1.0000\n",
      "Epoch 00165: val_loss improved from 0.10116 to 0.10094, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9524\n",
      "Epoch 166/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0808 - accuracy: 1.0000\n",
      "Epoch 00166: val_loss did not improve from 0.10094\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9524\n",
      "Epoch 167/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0807 - accuracy: 1.0000\n",
      "Epoch 00167: val_loss did not improve from 0.10094\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0837 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9524\n",
      "Epoch 168/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0843 - accuracy: 0.9459\n",
      "Epoch 00168: val_loss did not improve from 0.10094\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0851 - accuracy: 0.9524 - val_loss: 0.1043 - val_accuracy: 0.9524\n",
      "Epoch 169/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0873 - accuracy: 0.9722\n",
      "Epoch 00169: val_loss did not improve from 0.10094\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0820 - accuracy: 0.9762 - val_loss: 0.1010 - val_accuracy: 0.9524\n",
      "Epoch 170/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0875 - accuracy: 1.0000\n",
      "Epoch 00170: val_loss improved from 0.10094 to 0.10019, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9524\n",
      "Epoch 171/175\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.0817 - accuracy: 1.0000\n",
      "Epoch 00171: val_loss improved from 0.10019 to 0.09944, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9524\n",
      "Epoch 172/175\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 1.0000\n",
      "Epoch 00172: val_loss did not improve from 0.09944\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0805 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9524\n",
      "Epoch 173/175\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.0745 - accuracy: 1.0000\n",
      "Epoch 00173: val_loss improved from 0.09944 to 0.09918, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9524\n",
      "Epoch 174/175\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.0758 - accuracy: 1.0000\n",
      "Epoch 00174: val_loss did not improve from 0.09918\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9524\n",
      "Epoch 175/175\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.0807 - accuracy: 1.0000\n",
      "Epoch 00175: val_loss did not improve from 0.09918\n",
      "42/42 [==============================] - 1s 19ms/sample - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9524\n"
     ]
    }
   ],
   "source": [
    "\"\"\" train the model \"\"\"\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "siamese.compile(loss=utils.loss(1), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# siamese.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "siamese.summary()\n",
    "history = siamese.fit([x_train_1, x_train_2],\n",
    "    labels_train,\n",
    "    validation_data=([x_val_1, x_val_2], labels_val),\n",
    "    batch_size=1,\n",
    "    epochs=175,   # 175 for contrastive 100 for cross ent\n",
    "    callbacks = [checkpointer, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5219b8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "utils.plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb37692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the constrastive loss\n",
    "utils.plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ebb1ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296/1296 [==============================] - 5s 4ms/sample - loss: 0.0959 - accuracy: 0.9506\n",
      "test loss, test acc: [0.09593788690773057, 0.9506173]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Test the model \"\"\"\n",
    "results = siamese.evaluate([x_test_1, x_test_2], labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be00d433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28685403, 0.08015718, 0.6024718 , ..., 0.07277565, 0.13839976,\n",
       "       0.0345658 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = siamese.predict([x_test_1, x_test_2]).squeeze()\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4ec4ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred = Y_pred > .5\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f3303c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = labels_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c08c7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on test data\n",
      "Accuracy: 0.9506172839506173\n",
      "Precision: 0.955056179775281\n",
      "Recall: 0.9506172839506173\n",
      "ROC AUC: 0.9506172839506173\n",
      "F1: 0.9504965622612681\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluate on test data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3661b5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)    \n",
    "# cm_display = ConfusionMatrixDisplay(cm, labels_test).plot()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10419799",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ff4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
