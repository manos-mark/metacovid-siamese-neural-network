{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/manos-mark/metacovid-siamese-neural-network/blob/main/Siamese_NN_for_MetaCovid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Transfer Learning\n\nIn this notebook, we are going to use pre-trained networks to solve covid diagnosis challenge. Specifically, we will use a network trained on [ImageNet](http://www.image-net.org/). ImageNet is a massive dataset with over 1 million labeled images in 1,000 categories.\n\nThese pre-trained models work astonishingly well as feature detectors for images they weren't trained on. Using a pre-trained network on images not in the training set is called **Transfer Learning**. Here we'll use transfer learning to train a network that can classify our covid, non-covid and pneumonia classes.","metadata":{"id":"2muxqaxvTlzk"}},{"cell_type":"markdown","source":"## Import Resources","metadata":{"id":"9QNYGxmtIXQP"}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"BIlEbfVnroms","execution":{"iopub.status.busy":"2021-10-11T15:41:34.434165Z","iopub.execute_input":"2021-10-11T15:41:34.434577Z","iopub.status.idle":"2021-10-11T15:41:34.561558Z","shell.execute_reply.started":"2021-10-11T15:41:34.434483Z","shell.execute_reply":"2021-10-11T15:41:34.560620Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport os\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications import vgg16, imagenet_utils\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.metrics import binary_crossentropy\nfrom tensorflow.keras.layers import Dense, Flatten, Input, Lambda, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools","metadata":{"id":"BmUJmdTpU1Pz","execution":{"iopub.status.busy":"2021-10-11T16:14:19.216834Z","iopub.execute_input":"2021-10-11T16:14:19.217291Z","iopub.status.idle":"2021-10-11T16:14:19.244161Z","shell.execute_reply.started":"2021-10-11T16:14:19.217246Z","shell.execute_reply":"2021-10-11T16:14:19.242091Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)","metadata":{"id":"V9eJKqfJromz","execution":{"iopub.status.busy":"2021-10-11T15:41:45.239760Z","iopub.execute_input":"2021-10-11T15:41:45.240101Z","iopub.status.idle":"2021-10-11T15:41:45.246260Z","shell.execute_reply.started":"2021-10-11T15:41:45.240062Z","shell.execute_reply":"2021-10-11T15:41:45.245058Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print('Using:')\nprint('\\t\\u2022 TensorFlow version:', tf.__version__)\nprint('\\t\\u2022 tf.keras version:', tf.keras.__version__)\nprint('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')","metadata":{"id":"_Abet3-Yydgw","outputId":"6e6ba2b9-62b5-4bd5-a0d8-6dd19770a65e","execution":{"iopub.status.busy":"2021-10-11T15:41:47.616929Z","iopub.execute_input":"2021-10-11T15:41:47.617635Z","iopub.status.idle":"2021-10-11T15:41:49.899282Z","shell.execute_reply.started":"2021-10-11T15:41:47.617603Z","shell.execute_reply":"2021-10-11T15:41:49.898359Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Load the Dataset","metadata":{"id":"RMr2MeTCIhJd"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive/')","metadata":{"id":"zScJ4MGrqKi-","outputId":"2d563108-704d-407d-d75d-b7a732664df4","execution":{"iopub.status.busy":"2021-10-11T15:41:53.905535Z","iopub.execute_input":"2021-10-11T15:41:53.905855Z","iopub.status.idle":"2021-10-11T15:41:53.910917Z","shell.execute_reply.started":"2021-10-11T15:41:53.905811Z","shell.execute_reply":"2021-10-11T15:41:53.909666Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# base_dir = '/content/drive/MyDrive/Datasets/covid/'\nbase_dir = '../input/covid-normal-pneumonia-cxray/'\n\ntrain_dir = os.path.join(base_dir, 'train', 'train')\nval_dir = os.path.join(base_dir, 'validation', 'validation')\ntest_dir = os.path.join(base_dir, 'test', 'test')\n\ntrain_covid_dir = os.path.join(train_dir, 'covid')\ntrain_normal_dir = os.path.join(train_dir, 'normal')\ntrain_pneumonia_dir = os.path.join(train_dir, 'pneumonia')\n\nval_covid_dir = os.path.join(val_dir, 'covid')\nval_normal_dir = os.path.join(val_dir, 'normal')\nval_pneumonia_dir = os.path.join(val_dir, 'pneumonia')\n\ntest_covid_dir = os.path.join(test_dir, 'covid')\ntest_normal_dir = os.path.join(test_dir, 'normal')\ntest_pneumonia_dir = os.path.join(test_dir, 'pneumonia')","metadata":{"id":"vByiTDeFyMBv","execution":{"iopub.status.busy":"2021-10-11T15:41:54.286690Z","iopub.execute_input":"2021-10-11T15:41:54.286979Z","iopub.status.idle":"2021-10-11T15:41:54.296405Z","shell.execute_reply.started":"2021-10-11T15:41:54.286943Z","shell.execute_reply":"2021-10-11T15:41:54.294635Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# def create_generators(batch_size, train_dir, val_dir, test_dir):\n#   preprocessor = ImageDataGenerator(\n#       rescale = 1 / 255.\n#   )\n\n#   train_generator = preprocessor.flow_from_directory(\n#       train_dir,\n#       # class_mode='categorical',\n#       target_size=(224,224),\n#       color_mode='rgb',\n#       shuffle=True,\n#       batch_size=batch_size\n#   )\n\n#   val_generator = preprocessor.flow_from_directory(\n#       val_dir,\n#       # class_mode='categorical',\n#       target_size=(224,224),\n#       color_mode='rgb',\n#       shuffle=False,\n#       batch_size=batch_size\n#   )\n\n#   test_generator = preprocessor.flow_from_directory(\n#       test_dir,\n#       # class_mode='categorical',\n#       target_size=(224,224),\n#       color_mode='rgb',\n#       shuffle=False,\n#       batch_size=batch_size\n#   )\n\n#   return train_generator, val_generator, test_generator","metadata":{"id":"XADyPCfpFORK","execution":{"iopub.status.busy":"2021-10-11T15:41:54.696353Z","iopub.execute_input":"2021-10-11T15:41:54.696722Z","iopub.status.idle":"2021-10-11T15:41:54.702411Z","shell.execute_reply.started":"2021-10-11T15:41:54.696692Z","shell.execute_reply":"2021-10-11T15:41:54.701324Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_batches = ImageDataGenerator(rescale = 1 / 255.).flow_from_directory(train_dir,\n                                                         target_size=(224,224),\n                                                         class_mode='categorical',\n                                                         shuffle=True,\n                                                         seed=42,\n                                                         batch_size=30)","metadata":{"id":"6hpGwS6MA7cx","outputId":"728563d6-6306-4200-f03d-b01dc99e3a4f","execution":{"iopub.status.busy":"2021-10-11T15:41:55.103828Z","iopub.execute_input":"2021-10-11T15:41:55.104537Z","iopub.status.idle":"2021-10-11T15:41:55.224391Z","shell.execute_reply.started":"2021-10-11T15:41:55.104510Z","shell.execute_reply":"2021-10-11T15:41:55.223504Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"val_batches = ImageDataGenerator(rescale = 1 / 255.).flow_from_directory(val_dir,\n                                                         target_size=(224,224),\n                                                         class_mode='categorical',\n                                                         shuffle=True,\n                                                         seed=42,\n                                                         batch_size=10)","metadata":{"id":"k4w17nKxBXK7","outputId":"0405a60e-7d1e-42d3-ef90-e761004ba307","execution":{"iopub.status.busy":"2021-10-11T15:41:55.684672Z","iopub.execute_input":"2021-10-11T15:41:55.684981Z","iopub.status.idle":"2021-10-11T15:41:55.800884Z","shell.execute_reply.started":"2021-10-11T15:41:55.684910Z","shell.execute_reply":"2021-10-11T15:41:55.800036Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_batches = ImageDataGenerator(rescale = 1 / 255.).flow_from_directory(test_dir,\n                                                         target_size=(224,224),\n                                                         class_mode='categorical',\n                                                         shuffle=False,\n                                                         seed=42,\n                                                         batch_size=10)","metadata":{"id":"GcG0x8TRBfIs","outputId":"434c4826-cb30-4a10-fbba-ec2eeff84e30","execution":{"iopub.status.busy":"2021-10-11T15:41:56.274316Z","iopub.execute_input":"2021-10-11T15:41:56.274729Z","iopub.status.idle":"2021-10-11T15:41:56.387735Z","shell.execute_reply.started":"2021-10-11T15:41:56.274698Z","shell.execute_reply":"2021-10-11T15:41:56.386527Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Explore the Dataset","metadata":{"id":"yotXUFkbI-9B"}},{"cell_type":"code","source":"num_covid_train = int(len(os.listdir(train_covid_dir)))\nnum_normal_train = int(len(os.listdir(train_normal_dir)))\nnum_pneumonia_train = int(len(os.listdir(train_pneumonia_dir)))\n\nnum_covid_val = int(len(os.listdir(val_covid_dir)))\nnum_normal_val = int(len(os.listdir(val_normal_dir)))\nnum_pneumonia_val = int(len(os.listdir(val_pneumonia_dir)))\n\n# num_covid_test = int(len(os.listdir(test_covid_dir)))\n# num_normal_test = int(len(os.listdir(test_normal_dir)))\n# num_pneumonia_test = int(len(os.listdir(test_pneumonia_dir)))\n\nprint('The dataset contains:')\nprint(f'\\u2022 %d training images'%(num_covid_train + num_normal_train + num_pneumonia_train))\nprint(f'\\u2022 %d validation images'%(num_covid_val + num_normal_val + num_pneumonia_val))\n# print(f'\\u2022 %d test images'%(num_covid_test + num_normal_test + num_pneumonia_test))\n\nprint('\\nThe training set contains:')\nprint(f'\\u2022 %d covid images'%(num_covid_train))\nprint(f'\\u2022 %d normal images'%(num_normal_train))\nprint(f'\\u2022 %d pneumonia images'%(num_pneumonia_train))\n\nprint('\\nThe validation set contains:')\nprint(f'\\u2022 %d covid images'%(num_covid_val))\nprint(f'\\u2022 %d normal images'%(num_normal_val))\nprint(f'\\u2022 %d pneumonia images'%(num_pneumonia_val))\n\n# print('\\nThe test set contains:')\n# print(f'\\u2022 %d covid images'%(num_covid_test))\n# print(f'\\u2022 %d normal images'%(num_normal_test))\n# print(f'\\u2022 %d pneumonia images'%(num_pneumonia_test))","metadata":{"id":"V7Vii2eIEBPl","outputId":"33d79750-cf9d-4955-afb8-0ca49bd8eaa8","execution":{"iopub.status.busy":"2021-10-11T15:41:57.636806Z","iopub.execute_input":"2021-10-11T15:41:57.637188Z","iopub.status.idle":"2021-10-11T15:41:57.655701Z","shell.execute_reply.started":"2021-10-11T15:41:57.637159Z","shell.execute_reply":"2021-10-11T15:41:57.654173Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# from sklearn.datasets import load_files\n# from keras.utils import np_utils\n# import numpy as np\n \n# def load_dataset(path):\n#     data = load_files(path)\n#     paths = np.array(data['filenames'])\n#     targets = np_utils.to_categorical(np.array(data['target']))\n#     return paths, targets\n \n# test_files, test_targets = load_dataset('small_data/test')\n# from keras.preprocessing import image  \n# from keras.applications.vgg16 import preprocess_input\n# from tqdm import tqdm\n \n# def path_to_tensor(img_path):\n#     img = image.load_img(img_path, target_size=(224, 224))\n#     x = image.img_to_array(img)\n#     return np.expand_dims(x, axis=0)\n \n# def paths_to_tensor(img_paths):\n#     list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n#     return np.vstack(list_of_tensors)\n \n# test_tensors = preprocess_input(paths_to_tensor(test_files))\n# print('\\nTesting loss: {:.4f}\\nTesting accuracy: {:.4f}'.format(*new_model.evaluate(test_tensors, test_targets)))\n","metadata":{"id":"6UjIMF4nHo3-","execution":{"iopub.status.busy":"2021-10-11T15:41:58.083278Z","iopub.execute_input":"2021-10-11T15:41:58.083914Z","iopub.status.idle":"2021-10-11T15:41:58.092291Z","shell.execute_reply.started":"2021-10-11T15:41:58.083884Z","shell.execute_reply":"2021-10-11T15:41:58.091247Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_batches.next()[0].shape","metadata":{"id":"mNjcjgpDLHek","outputId":"f15d0beb-0f62-4178-fef8-c7a6e70bfb19","execution":{"iopub.status.busy":"2021-10-11T15:41:58.792725Z","iopub.execute_input":"2021-10-11T15:41:58.793638Z","iopub.status.idle":"2021-10-11T15:41:59.862066Z","shell.execute_reply.started":"2021-10-11T15:41:58.793606Z","shell.execute_reply":"2021-10-11T15:41:59.861193Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# class_names = train_batches.class_indices.keys()\n\n# plt.figure(figsize=(10, 10))\n# for images, labels in train_batches.take(1):\n#   for i in range(9):\n#     ax = plt.subplot(3, 3, i + 1)\n#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n#     plt.title(class_names[labels[i]])\n#     plt.axis(\"off\")","metadata":{"id":"IRoQodo3dXY2","execution":{"iopub.status.busy":"2021-10-11T15:41:59.864060Z","iopub.execute_input":"2021-10-11T15:41:59.864411Z","iopub.status.idle":"2021-10-11T15:41:59.871775Z","shell.execute_reply.started":"2021-10-11T15:41:59.864375Z","shell.execute_reply":"2021-10-11T15:41:59.869950Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Create Pipeline\n\nThe pre-trained model we are going to use requires that the input images have color values in the range `[0,1]` and a size of `(224, 224)`. We will therefore have to normalize the pixel values of our images and resize them to the appropriate size. We can normalize our pixel values in the usual way by dividing the original pixel values by `255` and to resize our images we can use the `tf.image.resize()` function.","metadata":{"id":"iXdiexgZBnAq"}},{"cell_type":"code","source":"# # TODO: change size to 100????\n# # TODO: histogram matching\n\n# batch_size = 32\n# image_size = 224\n\n# # num_training_examples = (total_num_examples * train_split) // 100\n\n# def normalize(arr):\n#     \"\"\"\n#     Linear normalization\n#     http://en.wikipedia.org/wiki/Normalization_%28image_processing%29\n#     \"\"\"\n#     arr = arr.astype('float')\n#     # Do not touch the alpha channel\n#     for i in range(3):\n#         minval = arr[...,i].min()\n#         maxval = arr[...,i].max()\n#         if minval != maxval:\n#             arr[...,i] -= minval\n#             arr[...,i] *= (255.0/(maxval-minval))\n#     return arr\n\n# def format_image(image, label):\n#     image = tf.cast(image, tf.float32)\n#     image = tf.image.resize(image, (image_size, image_size))\n#     image /= 255\n#     return image, label\n\n\n# # train_batches = train_batches.shuffle(num_training_examples//4).map(format_image).map(normalize).batch(batch_size).prefetch(1)\n# train_batches = train_batches.map(format_image).map(normalize).prefetch(1)\n# train_batches\n# # val_batches = val_batches.map(format_image).map(normalize).batch(batch_size).prefetch(1)\n# # test_batches = test_batches.map(format_image).map(normalize).batch(batch_size).prefetch(1)","metadata":{"id":"kkGBYnL-BqH1","execution":{"iopub.status.busy":"2021-10-11T15:42:00.254511Z","iopub.execute_input":"2021-10-11T15:42:00.254815Z","iopub.status.idle":"2021-10-11T15:42:00.261835Z","shell.execute_reply.started":"2021-10-11T15:42:00.254787Z","shell.execute_reply":"2021-10-11T15:42:00.260412Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Transfer Learning \n","metadata":{"id":"9OFVEQQSleKF"}},{"cell_type":"code","source":"base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))","metadata":{"id":"59qI5xtTBjk7","execution":{"iopub.status.busy":"2021-10-11T15:42:01.353833Z","iopub.execute_input":"2021-10-11T15:42:01.354328Z","iopub.status.idle":"2021-10-11T15:42:02.846185Z","shell.execute_reply.started":"2021-10-11T15:42:01.354297Z","shell.execute_reply":"2021-10-11T15:42:02.845325Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"It is important that we freeze the weights and biases in our pre-trained model so that we don't modify them during training. We can do this by setting the parameters of our model to non-trainable, as shown in the code below.","metadata":{"id":"JTJTOxkfnlgd"}},{"cell_type":"code","source":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))","metadata":{"id":"CqEpStotcnmC","outputId":"470166db-eee6-4fbc-c52d-0b4ede1152ab","execution":{"iopub.status.busy":"2021-10-11T15:42:04.133867Z","iopub.execute_input":"2021-10-11T15:42:04.134726Z","iopub.status.idle":"2021-10-11T15:42:04.142776Z","shell.execute_reply.started":"2021-10-11T15:42:04.134693Z","shell.execute_reply":"2021-10-11T15:42:04.140639Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Unfreeze the base_model and set the bottom layers to be un-trainable.\n# Then, recompile the model (necessary for these changes to take effect), and resume training.\nbase_model.trainable = True\n\nfine_tune_at = 0\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable = False\n\nbase_model.summary()","metadata":{"id":"AqtAGNlZnjvE","outputId":"ca4779c2-df0a-4b27-91a6-4ce2bb76927f","execution":{"iopub.status.busy":"2021-10-11T16:30:00.582161Z","iopub.execute_input":"2021-10-11T16:30:00.583147Z","iopub.status.idle":"2021-10-11T16:30:00.607487Z","shell.execute_reply.started":"2021-10-11T16:30:00.583111Z","shell.execute_reply":"2021-10-11T16:30:00.605574Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## Build the Convolutional Model","metadata":{"id":"_VEEN4oUoZMW"}},{"cell_type":"code","source":"last_output = base_model.output\n\nx = Dropout(0.5)(last_output)\n\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\n\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\n\nx = Flatten()(x)\n# x = Dense(units=5120, activation='sigmoid', kernel_regularizer=l2(1e-4))(x)\nx = Dense(3, activation='softmax')(x)\n\nembedding_network = Model(inputs=[base_model.input], outputs=[x])\n\n# reduce = ReduceLROnPlateau()\noptimizer = Adam(learning_rate=0.000001) \n\nembedding_network.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\nembedding_network.summary()","metadata":{"id":"le6eV8RfoQHc","outputId":"b877a16e-eca3-413c-d690-d1e53dff677b","execution":{"iopub.status.busy":"2021-10-11T16:30:04.670309Z","iopub.execute_input":"2021-10-11T16:30:04.670676Z","iopub.status.idle":"2021-10-11T16:30:04.792950Z","shell.execute_reply.started":"2021-10-11T16:30:04.670647Z","shell.execute_reply":"2021-10-11T16:30:04.792106Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## Train the Convolutional model","metadata":{"id":"SMjLsIIFILgN"}},{"cell_type":"code","source":"# Using early stopping will terminate the training process if the validation\n# loss is not improving for 5 continues epochs\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10)\n\ncheckpointer = ModelCheckpoint(filepath='model.weights.best.embedding_network.hdf5', verbose=1, \n                               save_best_only=True)\n\nhistory = embedding_network.fit(\n    train_batches,\n    validation_data=val_batches,\n    epochs=100,\n    verbose=1,\n    shuffle=True,\n    callbacks=[early_stopping, checkpointer]\n)","metadata":{"id":"gRwMTjJ5IQER","outputId":"ea1d404d-6eff-4f5d-ae1a-a956cd52dc13","execution":{"iopub.status.busy":"2021-10-11T16:30:08.522179Z","iopub.execute_input":"2021-10-11T16:30:08.522503Z","iopub.status.idle":"2021-10-11T16:46:05.523185Z","shell.execute_reply.started":"2021-10-11T16:30:08.522474Z","shell.execute_reply":"2021-10-11T16:46:05.522215Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate the Convolutional model","metadata":{"id":"is6rI1xWWUlh"}},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"id":"RTEcoRMgWXDm","execution":{"iopub.status.busy":"2021-10-11T16:46:05.525602Z","iopub.execute_input":"2021-10-11T16:46:05.525970Z","iopub.status.idle":"2021-10-11T16:46:05.819254Z","shell.execute_reply.started":"2021-10-11T16:46:05.525922Z","shell.execute_reply":"2021-10-11T16:46:05.818332Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"id":"yQU8l7ePW2UT","execution":{"iopub.status.busy":"2021-10-11T16:46:05.820903Z","iopub.execute_input":"2021-10-11T16:46:05.821216Z","iopub.status.idle":"2021-10-11T16:46:06.136553Z","shell.execute_reply.started":"2021-10-11T16:46:05.821173Z","shell.execute_reply":"2021-10-11T16:46:06.135632Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"## Define the Siamese architecture\n\nThere are be two input layers, each leading to its own network, which produces embeddings. A Lambda layer then merges them using an Manhatan or Euclidean distance and the merged output is fed to the final network.","metadata":{"id":"QZHNMI79EyIw"}},{"cell_type":"code","source":"# Provided two tensors t1 and t2\n# Euclidean distance = sqrt(sum(square(t1-t2)))\ndef euclidean_distance(vects):\n    \"\"\"Find the Euclidean distance between two vectors.\n\n    Arguments:\n        vects: List containing two tensors of same length.\n\n    Returns:\n        Tensor containing euclidean distance\n        (as floating point value) between vectors.\n    \"\"\"\n\n    x, y = vects\n    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n\n# Provided two tensors t1 and t2\n# Manhatan distance = abs(t1-t2)\ndef manhatan_distance(vects):\n    \"\"\"Find the Euclidean distance between two vectors.\n\n    Arguments:\n        vects: List containing two tensors of same length.\n\n    Returns:\n        Tensor containing manhatan distance\n        (as floating point value) between vectors.\n    \"\"\"\n\n    x, y = vects\n    return tf.math.abs(x - y)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T15:10:03.389743Z","iopub.execute_input":"2021-10-11T15:10:03.390149Z","iopub.status.idle":"2021-10-11T15:10:03.39697Z","shell.execute_reply.started":"2021-10-11T15:10:03.390102Z","shell.execute_reply":"2021-10-11T15:10:03.396077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As mentioned above, Siamese Network share weights between\n# tower networks (sister networks). To allow this, we will use\n# same embedding network for both tower networks.\ninput_1 = Input((224,224,3))\ninput_2 = Input((224,224,3))\n\ntower_1 = embedding_network(input_1)\ntower_2 = embedding_network(input_2)\n\nmerge_layer = Lambda(manhatan_distance)([tower_1, tower_2])\n# normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\noutput_layer = Dense(1, activation=\"sigmoid\")(merge_layer)\n\nsiamese = Model(inputs=[input_1, input_2], outputs=[output_layer])\nsiamese.summary()","metadata":{"id":"XC2i5onCCI7_","outputId":"54c8ed0c-5052-4ceb-c5d0-f37cd06654ed","execution":{"iopub.status.busy":"2021-10-11T15:08:14.74444Z","iopub.execute_input":"2021-10-11T15:08:14.744704Z","iopub.status.idle":"2021-10-11T15:08:14.859732Z","shell.execute_reply.started":"2021-10-11T15:08:14.74467Z","shell.execute_reply":"2021-10-11T15:08:14.858356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ZcIfe-Gd-ABn","execution":{"iopub.status.busy":"2021-10-11T15:08:14.860932Z","iopub.status.idle":"2021-10-11T15:08:14.861459Z","shell.execute_reply.started":"2021-10-11T15:08:14.86122Z","shell.execute_reply":"2021-10-11T15:08:14.861244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compile and train the model with the contrastive loss\n","metadata":{"id":"BbPAFZv1C5LS"}},{"cell_type":"markdown","source":"### Define the constrastive Loss\n","metadata":{"id":"pKdVElkUCqd6"}},{"cell_type":"code","source":"def loss(margin=1):\n    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n\n  Arguments:\n      margin: Integer, defines the baseline for distance for which pairs\n              should be classified as dissimilar. - (default is 1).\n\n  Returns:\n      'constrastive_loss' function with data ('margin') attached.\n  \"\"\"\n\n# Contrastive loss = mean( (1-true_value) * square(prediction) +\n#                         true_value * square( max(margin-prediction, 0) ))\ndef contrastive_loss(y_true, y_pred):\n    \"\"\"Calculates the constrastive loss.\n\n  Arguments:\n      y_true: List of labels, each label is of type float32.\n      y_pred: List of predictions of same length as of y_true,\n              each label is of type float32.\n\n  Returns:\n      A tensor containing constrastive loss as floating point value.\n  \"\"\"\n\n    square_pred = tf.math.square(y_pred)\n    margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n    return tf.math.reduce_mean(\n        (1 - y_true) * square_pred + (y_true) * margin_square\n    )\n\nreturn contrastive_loss","metadata":{"id":"e4nNHeGWCt45","execution":{"iopub.status.busy":"2021-10-11T15:08:14.863004Z","iopub.status.idle":"2021-10-11T15:08:14.863431Z","shell.execute_reply.started":"2021-10-11T15:08:14.863208Z","shell.execute_reply":"2021-10-11T15:08:14.86323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"siamese_contrastive = siamese\nsiamese_contrastive.compile(loss=loss(margin=1), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\nsiamese_contrastive.summary()","metadata":{"id":"js6QzuE1C4LN","outputId":"27eab5bd-7088-4f8c-dcb9-06e7f59da7d3","execution":{"iopub.status.busy":"2021-10-11T15:08:14.865007Z","iopub.status.idle":"2021-10-11T15:08:14.865418Z","shell.execute_reply.started":"2021-10-11T15:08:14.865196Z","shell.execute_reply":"2021-10-11T15:08:14.865218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the model with contrastive loss","metadata":{"id":"R1eW1qrJFcjn"}},{"cell_type":"code","source":"# Using early stopping will terminate the training process if the validation\n# loss is not improving for 5 continues epochs\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5)\n\ncheckpointer = ModelCheckpoint(filepath='model.weights.best.siamese_contrastive.hdf5', verbose=1, \n                               save_best_only=True)\n\nhistory_contrastive = siamese_contrastive.fit(\n    [x_train_1, x_train_2],\n    labels_train,\n    validation_data=([x_val_1, x_val_2], labels_val),\n    batch_size=batch_size,\n    callbacks=[early_stopping, checkpointer],\n    epochs=2\n)","metadata":{"id":"P3nNn38EFmNf","execution":{"iopub.status.busy":"2021-10-11T15:08:14.86682Z","iopub.status.idle":"2021-10-11T15:08:14.867244Z","shell.execute_reply.started":"2021-10-11T15:08:14.867018Z","shell.execute_reply":"2021-10-11T15:08:14.867039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compile and train the model with binary cross entropy loss\n","metadata":{"id":"8vOVXFnKGKVn"}},{"cell_type":"code","source":"siamese_crossentropy = siamese\nsiamese_crossentropy.compile(loss='binary_cross_entropy', optimizer=\"RMSprop\", metrics=[\"accuracy\"])\nsiamese_crossentropy.summary()","metadata":{"id":"2fs0PElgGKV0","outputId":"28721763-c9d8-4ed8-c60b-e08d86a44385","execution":{"iopub.status.busy":"2021-10-11T15:08:14.868612Z","iopub.status.idle":"2021-10-11T15:08:14.869022Z","shell.execute_reply.started":"2021-10-11T15:08:14.868798Z","shell.execute_reply":"2021-10-11T15:08:14.86882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the model with binary cross entropy","metadata":{"id":"TU1jyJTVGKV5"}},{"cell_type":"code","source":"# Using early stopping will terminate the training process if the validation\n# loss is not improving for 5 continues epochs\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5)\n\ncheckpointer = ModelCheckpoint(filepath='model.weights.best.siamese_crossentropy.hdf5', verbose=1, \n                               save_best_only=True)\n\nhistory_crossentropy = siamese_crossentropy.fit(\n    [x_train_1, x_train_2],\n    labels_train,\n    validation_data=([x_val_1, x_val_2], labels_val),\n    batch_size=batch_size,\n    callbacks=[early_stopping, checkpointer],\n    epochs=2\n)","metadata":{"id":"N1g7kuDOGKV7","outputId":"7817f985-f0ce-442d-bb93-38ca12f8aab1","execution":{"iopub.status.busy":"2021-10-11T15:08:14.870397Z","iopub.status.idle":"2021-10-11T15:08:14.870966Z","shell.execute_reply.started":"2021-10-11T15:08:14.87073Z","shell.execute_reply":"2021-10-11T15:08:14.870753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the Model Using a GPU\n\nWith our model built, we now need to train the new classification layer, but this time we're using a **really deep** neural network. If you try to train this on a CPU like normal, it will take a long, long time. Instead, we're going to use a GPU to do the calculations. On a GPU, linear algebra computations are done in parallel, leading to 100x increased training speeds. TensorFlow will transparently run on a single GPU without requiring that we make changes to our code. With TensorFlow, it's also possible to train on multiple GPUs, further decreasing training time, but this requires that we make changes to our code to incorporate [distributed training](https://www.tensorflow.org/guide/distributed_training). \n\nWe can use the `tf.test.is_gpu_available()` function to confirm that TensorFlow is using the GPU.","metadata":{"id":"ZSy0p05YpDmM"}},{"cell_type":"code","source":"print('Is there a GPU Available:', tf.test.is_gpu_available())","metadata":{"id":"7BsmVnFCrT5u","outputId":"f6b8d0c7-cdf3-4d1b-cbcb-123c936df4fe","execution":{"iopub.status.busy":"2021-10-11T15:08:14.872294Z","iopub.status.idle":"2021-10-11T15:08:14.87275Z","shell.execute_reply.started":"2021-10-11T15:08:14.8725Z","shell.execute_reply":"2021-10-11T15:08:14.872522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TensorFlow uses different string identifiers for CPUs and GPUs. For example, TensorFlow will use the identifier:\n\n```python\n'/CPU:0'\n```\nfor the CPU of your machine; and it will use the identifier:\n\n```python\n'/GPU:0'\n```\nfor the first GPU of your machine that is visible to TensorFlow. If your system has both devices, `/CPU:0` and `/GPU:0`, by default the GPU devices will be given priority when preforming TensorFlow operations (given that the TensorFlow operations have both CPU and GPU implementations). For example, the TensorFlow `tf.matmul` operation has both CPU and GPU kernels, therefore, the `/GPU:0` device will be selected to run `tf.matmul` unless you explicitly request running it on another device.\n\n### Manual Device Placement\n\nIf you would like a particular TensorFlow operation to run on the device of your choice, instead of what's automatically selected for you by default, you can use:\n\n```python\n# Place tensors on the CPU\nwith tf.device('/CPU:0'):\n    perform operations\n```\n\nto have operations run on the CPU; and you can use:\n  \n```python\n# Place tensors on the GPU\nwith tf.device('/GPU:0'):\n    perform operations\n```\n\nto have operations run on the GPU.\n\n#### Example\n\nLet's assume we have a system that has both devices, `/CPU:0` and `/GPU:0`. What will happen if we run the code below?\n\n```python\n# Place tensors on the CPU\nwith tf.device('/CPU:0'):\n    a = tf.random.normal(...)\n    b = tf.random.normal(...)\n\nc = tf.matmul(a, b)\n```\n\nThe above code will create both `a` and `b` using the CPU because we manually assigned those statements to the \n`/CPU:0` device using the `with tf.device('/CPU:0')` code block. However, since the statement `c = tf.matmul(a, b)` is NOT inside the `with tf.device('/CPU:0')` code block, then TensorFlow will run the `tf.matmul` operation on the `/GPU:0` device. TensorFlow will automatically copy tensors between devices if required.\n\nIn the code below, we will multiply matrices of increasing size using both the CPU and GPU so you can see the difference in execution time. You will see, that as the size of the matrices increase, the execution time on the CPU increases rapidly, but on the GPU it stays constant.","metadata":{"id":"_3BA5rWQuVaF"}},{"cell_type":"code","source":"def plot_times(max_size = 650):\n    device_times = {'/GPU:0':[], '/CPU:0':[]}\n    matrix_sizes = range(450, max_size, 50)\n    len_matrix = len(matrix_sizes)\n\n    for i, size in enumerate(matrix_sizes):\n        for device_name in device_times.keys():\n            with tf.device(device_name):\n                m1 = tf.random.uniform(shape=(size,size), dtype=tf.float16)\n                m2 = tf.random.uniform(shape=(size,size), dtype=tf.float16)\n                start_time = time.time()\n                dot_operation = tf.matmul(m2, m1)\n                time_taken = time.time() - start_time\n                \n                if i > 0:\n                    device_times[device_name].append(time_taken)\n                    \n        percent_complete = (i + 1) / len_matrix\n        print('\\rPerforming Calculations. Please Wait... {:.0%} Complete'.format(percent_complete), end = '')\n    \n    matrix_sizes = matrix_sizes[1:]\n    \n    plt.figure(figsize=(10,7))\n    \n    plt.plot(matrix_sizes, device_times['/CPU:0'], 'o-', color='magenta', linewidth = 2, label = 'CPU')\n    plt.plot(matrix_sizes, device_times['/GPU:0'], 'o-', color='cyan', linewidth = 2, label='GPU')\n    ax = plt.gca()\n    ax.set_facecolor('black')\n    plt.grid()\n    plt.ylabel('Time (s)', color='white', fontsize = 20)\n    plt.xlabel('Matrix size',  color='white', fontsize = 20)\n    plt.legend(prop={'size': 15})\n    plt.show()\n    \nplot_times(850)","metadata":{"id":"vY9t-NQqronS","outputId":"1bed65bb-21bd-4db4-f21d-7db70dc43b31","execution":{"iopub.status.busy":"2021-10-11T15:08:14.87412Z","iopub.status.idle":"2021-10-11T15:08:14.874554Z","shell.execute_reply.started":"2021-10-11T15:08:14.874313Z","shell.execute_reply":"2021-10-11T15:08:14.874335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## Solution\n# model.compile(optimizer='adam',\n#               loss='sparse_categorical_crossentropy',\n#               metrics=['accuracy'])\n\n# EPOCHS = 2\n\n# history = model.fit(training_batches,\n#                     epochs=EPOCHS,\n#                     validation_data=validation_batches)\n\n\n\n# Using early stopping will terminate the training process if the validation\n# loss is not improving for 5 continues epochs\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5)\n\ncheckpointer = ModelCheckpoint(filepath='model.weights.best.siamese.hdf5', verbose=1, \n                               save_best_only=True)\n\nhistory = siamese.fit(\n    [x_train_1, x_train_2],\n    labels_train,\n    validation_data=([x_val_1, x_val_2], labels_val),\n    batch_size=batch_size,\n    callbacks=[early_stopping, checkpointer],\n    epochs=2\n)\n\n","metadata":{"id":"zsNPAHR9o7Gv","outputId":"da0f01cc-0f61-4218-d25c-3f7c48f7f8af","execution":{"iopub.status.busy":"2021-10-11T15:08:14.875919Z","iopub.status.idle":"2021-10-11T15:08:14.876334Z","shell.execute_reply.started":"2021-10-11T15:08:14.876104Z","shell.execute_reply":"2021-10-11T15:08:14.876125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Predictions","metadata":{"id":"VBfxg0GoPdiO"}},{"cell_type":"code","source":"# for image_batch, label_batch in testing_batches.take(1):\n#     ps = model.predict(image_batch)\n#     images = image_batch.numpy().squeeze()\n#     labels = label_batch.numpy()\n\n# plt.figure(figsize=(10,15))\n\n# for n in range(30):\n#     plt.subplot(6,5,n+1)\n#     plt.imshow(images[n], cmap = plt.cm.binary)\n#     color = 'green' if np.argmax(ps[n]) == labels[n] else 'red'\n#     plt.title(class_names[np.argmax(ps[n])], color=color)\n#     plt.axis('off')","metadata":{"id":"X_eKgwBe880Q","execution":{"iopub.status.busy":"2021-10-11T15:08:14.877725Z","iopub.status.idle":"2021-10-11T15:08:14.878141Z","shell.execute_reply.started":"2021-10-11T15:08:14.877924Z","shell.execute_reply":"2021-10-11T15:08:14.877946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"41kBLcTJVX3y"},"execution_count":null,"outputs":[]}]}