{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc42bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde1ea84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:\n",
      "\t• TensorFlow version: 2.1.0\n",
      "\t• tf.keras version: 2.2.4-tf\n",
      "\t• Running on GPU\n"
     ]
    }
   ],
   "source": [
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "print('Using:')\n",
    "print('\\t\\u2022 TensorFlow version:', tf.__version__)\n",
    "print('\\t\\u2022 tf.keras version:', tf.keras.__version__)\n",
    "print('\\t\\u2022 Running on GPU' if tf.test.is_gpu_available() else '\\t\\u2022 GPU device not found. Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e983b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 images belonging to 3 classes.\n",
      "The train set contains 21\n",
      "Found 21 images belonging to 3 classes.\n",
      "The valid set contains 21\n",
      "Found 648 images belonging to 3 classes.\n",
      "The test set contains 648\n"
     ]
    }
   ],
   "source": [
    "basedir = os.path.join(\"C:\\\\Users\\\\aktas\\\\Desktop\\\\VIBOT\\\\3.semester\\\\Meta-Learning\\\\project_final\\\\metacovid-siamese-neural-network\", \"dataset\", \"siamese\") \n",
    "\n",
    "train_image_list, train_y_list = utils.load_images(basedir, 'train', (100,100))\n",
    "print(\"The train set contains\",len(train_image_list)) \n",
    "\n",
    "valid_image_list, valid_y_list = utils.load_images(basedir, 'validation', (100,100))   \n",
    "print(\"The valid set contains\", len(valid_image_list))  \n",
    "\n",
    "test_image_list, test_y_list = utils.load_images(basedir, 'test', (100,100))   \n",
    "print(\"The test set contains\", len(test_image_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e510ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pairs for training 42\n",
      "number of pairs for validation 42\n",
      "number of pairs for test 1296\n"
     ]
    }
   ],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train = utils.make_pairs(train_image_list, train_y_list)\n",
    "\n",
    "# make validation pairs\n",
    "pairs_val, labels_val = utils.make_pairs(valid_image_list, valid_y_list)\n",
    "\n",
    "# make test pairs\n",
    "pairs_test, labels_test = utils.make_pairs(test_image_list, test_y_list)\n",
    "\n",
    "x_train_1 = pairs_train[:, 0]  \n",
    "x_train_2 = pairs_train[:, 1]\n",
    "print(\"number of pairs for training\", np.shape(x_train_1)[0]) \n",
    "\n",
    "x_val_1 = pairs_val[:, 0] \n",
    "x_val_2 = pairs_val[:, 1]\n",
    "print(\"number of pairs for validation\", np.shape(x_val_1)[0]) \n",
    "\n",
    "x_test_1 = pairs_test[:, 0] \n",
    "x_test_2 = pairs_test[:, 1]\n",
    "print(\"number of pairs for test\", np.shape(x_test_1)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ab81282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 5120)         14748995    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "SIAMESE_MODEL_FNAME = 'siamese_network.h5'\n",
    "EMBEDDING_MODEL_FNAME = 'embedding_network.h5'\n",
    "\n",
    "input_1 = Input((100,100,3))\n",
    "input_2 = Input((100,100,3))\n",
    "\n",
    "embedding_network = tf.keras.models.load_model(EMBEDDING_MODEL_FNAME)\n",
    "embedding_network.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential() \n",
    "for layer in embedding_network.layers:  \n",
    "    model.add(layer) \n",
    "\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dense(5120, name='den', activation='sigmoid', kernel_regularizer='l2')) \n",
    " \n",
    "output_1 = model(input_1) \n",
    "output_2 = model(input_2) \n",
    " \n",
    "merge_layer = Lambda(utils.manhattan_distance)([output_1, output_2]) \n",
    "output_layer = Dense(1, activation=\"sigmoid\")(merge_layer) \n",
    "siamese = Model(inputs=[input_1, input_2], outputs=output_layer) \n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84bde165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" callbacks \"\"\"\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.0001)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='siamese_network.h5', verbose=1, \n",
    "                                save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aa63961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 5120)         14748995    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2           lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,748,997\n",
      "Trainable params: 20,482\n",
      "Non-trainable params: 14,728,515\n",
      "__________________________________________________________________________________________________\n",
      "Train on 42 samples, validate on 42 samples\n",
      "Epoch 1/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6532 - accuracy: 0.5854\n",
      "Epoch 00001: val_loss improved from inf to 0.65636, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 4s 85ms/sample - loss: 0.6501 - accuracy: 0.5714 - val_loss: 0.6564 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6374 - accuracy: 0.6098\n",
      "Epoch 00002: val_loss improved from 0.65636 to 0.64795, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6403 - accuracy: 0.6190 - val_loss: 0.6480 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.6337 - accuracy: 0.6667\n",
      "Epoch 00003: val_loss improved from 0.64795 to 0.64202, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6335 - accuracy: 0.6667 - val_loss: 0.6420 - val_accuracy: 0.5952\n",
      "Epoch 4/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6257 - accuracy: 0.6829\n",
      "Epoch 00004: val_loss improved from 0.64202 to 0.63777, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6287 - accuracy: 0.6905 - val_loss: 0.6378 - val_accuracy: 0.6429\n",
      "Epoch 5/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.6285 - accuracy: 0.7297\n",
      "Epoch 00005: val_loss improved from 0.63777 to 0.63492, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6249 - accuracy: 0.7381 - val_loss: 0.6349 - val_accuracy: 0.6429\n",
      "Epoch 6/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6222 - accuracy: 0.7500\n",
      "Epoch 00006: val_loss improved from 0.63492 to 0.63254, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6221 - accuracy: 0.7619 - val_loss: 0.6325 - val_accuracy: 0.6429\n",
      "Epoch 7/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6261 - accuracy: 0.7750\n",
      "Epoch 00007: val_loss improved from 0.63254 to 0.63082, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6200 - accuracy: 0.7619 - val_loss: 0.6308 - val_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.6150 - accuracy: 0.7297\n",
      "Epoch 00008: val_loss improved from 0.63082 to 0.62901, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6181 - accuracy: 0.7619 - val_loss: 0.6290 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6136 - accuracy: 0.8049\n",
      "Epoch 00009: val_loss improved from 0.62901 to 0.62779, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6166 - accuracy: 0.8095 - val_loss: 0.6278 - val_accuracy: 0.6905\n",
      "Epoch 10/100\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.6091 - accuracy: 0.8421\n",
      "Epoch 00010: val_loss improved from 0.62779 to 0.62670, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6155 - accuracy: 0.8571 - val_loss: 0.6267 - val_accuracy: 0.6905\n",
      "Epoch 11/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6176 - accuracy: 0.8718\n",
      "Epoch 00011: val_loss improved from 0.62670 to 0.62599, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6144 - accuracy: 0.8810 - val_loss: 0.6260 - val_accuracy: 0.6905\n",
      "Epoch 12/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.6170 - accuracy: 0.8649\n",
      "Epoch 00012: val_loss improved from 0.62599 to 0.62547, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6135 - accuracy: 0.8810 - val_loss: 0.6255 - val_accuracy: 0.6905\n",
      "Epoch 13/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6099 - accuracy: 0.8780\n",
      "Epoch 00013: val_loss improved from 0.62547 to 0.62472, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6128 - accuracy: 0.8810 - val_loss: 0.6247 - val_accuracy: 0.6905\n",
      "Epoch 14/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6151 - accuracy: 0.9231\n",
      "Epoch 00014: val_loss improved from 0.62472 to 0.62409, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6122 - accuracy: 0.9048 - val_loss: 0.6241 - val_accuracy: 0.7143\n",
      "Epoch 15/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6147 - accuracy: 0.8974\n",
      "Epoch 00015: val_loss improved from 0.62409 to 0.62328, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6115 - accuracy: 0.9048 - val_loss: 0.6233 - val_accuracy: 0.7143\n",
      "Epoch 16/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6107 - accuracy: 0.9000\n",
      "Epoch 00016: val_loss improved from 0.62328 to 0.62300, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6107 - accuracy: 0.9048 - val_loss: 0.6230 - val_accuracy: 0.7143\n",
      "Epoch 17/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6131 - accuracy: 0.9024\n",
      "Epoch 00017: val_loss improved from 0.62300 to 0.62249, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6101 - accuracy: 0.9048 - val_loss: 0.6225 - val_accuracy: 0.7381\n",
      "Epoch 18/100\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.6160 - accuracy: 0.8947\n",
      "Epoch 00018: val_loss improved from 0.62249 to 0.62189, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6095 - accuracy: 0.9048 - val_loss: 0.6219 - val_accuracy: 0.7381\n",
      "Epoch 19/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.5991 - accuracy: 0.9189\n",
      "Epoch 00019: val_loss improved from 0.62189 to 0.62131, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6090 - accuracy: 0.9048 - val_loss: 0.6213 - val_accuracy: 0.7381\n",
      "Epoch 20/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.6087 - accuracy: 0.8889\n",
      "Epoch 00020: val_loss improved from 0.62131 to 0.62109, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6084 - accuracy: 0.9048 - val_loss: 0.6211 - val_accuracy: 0.7381\n",
      "Epoch 21/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6108 - accuracy: 0.9268\n",
      "Epoch 00021: val_loss improved from 0.62109 to 0.62063, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6079 - accuracy: 0.9048 - val_loss: 0.6206 - val_accuracy: 0.7381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6044 - accuracy: 0.8974\n",
      "Epoch 00022: val_loss improved from 0.62063 to 0.61995, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6075 - accuracy: 0.9048 - val_loss: 0.6200 - val_accuracy: 0.7381\n",
      "Epoch 23/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6070 - accuracy: 0.9000\n",
      "Epoch 00023: val_loss improved from 0.61995 to 0.61982, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6069 - accuracy: 0.9048 - val_loss: 0.6198 - val_accuracy: 0.7381\n",
      "Epoch 24/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5974 - accuracy: 0.8974\n",
      "Epoch 00024: val_loss improved from 0.61982 to 0.61926, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6066 - accuracy: 0.9048 - val_loss: 0.6193 - val_accuracy: 0.7381\n",
      "Epoch 25/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6058 - accuracy: 0.9250\n",
      "Epoch 00025: val_loss improved from 0.61926 to 0.61895, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6061 - accuracy: 0.9048 - val_loss: 0.6190 - val_accuracy: 0.7381\n",
      "Epoch 26/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.6125 - accuracy: 0.9167\n",
      "Epoch 00026: val_loss improved from 0.61895 to 0.61853, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6057 - accuracy: 0.9048 - val_loss: 0.6185 - val_accuracy: 0.7381\n",
      "Epoch 27/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6084 - accuracy: 0.8974\n",
      "Epoch 00027: val_loss improved from 0.61853 to 0.61803, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6053 - accuracy: 0.9048 - val_loss: 0.6180 - val_accuracy: 0.7381\n",
      "Epoch 28/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.5951 - accuracy: 0.8919\n",
      "Epoch 00028: val_loss improved from 0.61803 to 0.61789, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6048 - accuracy: 0.9048 - val_loss: 0.6179 - val_accuracy: 0.7381\n",
      "Epoch 29/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.6078 - accuracy: 0.8919\n",
      "Epoch 00029: val_loss improved from 0.61789 to 0.61744, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6044 - accuracy: 0.9048 - val_loss: 0.6174 - val_accuracy: 0.7381\n",
      "Epoch 30/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.6041 - accuracy: 0.9250\n",
      "Epoch 00030: val_loss improved from 0.61744 to 0.61725, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6040 - accuracy: 0.9286 - val_loss: 0.6172 - val_accuracy: 0.7381\n",
      "Epoch 31/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.6008 - accuracy: 0.9268\n",
      "Epoch 00031: val_loss improved from 0.61725 to 0.61675, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6036 - accuracy: 0.9286 - val_loss: 0.6167 - val_accuracy: 0.7381\n",
      "Epoch 32/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.6102 - accuracy: 0.9167\n",
      "Epoch 00032: val_loss improved from 0.61675 to 0.61648, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6032 - accuracy: 0.9286 - val_loss: 0.6165 - val_accuracy: 0.7381\n",
      "Epoch 33/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.6031 - accuracy: 0.9167\n",
      "Epoch 00033: val_loss improved from 0.61648 to 0.61633, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6028 - accuracy: 0.9286 - val_loss: 0.6163 - val_accuracy: 0.7381\n",
      "Epoch 34/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5996 - accuracy: 0.9231\n",
      "Epoch 00034: val_loss improved from 0.61633 to 0.61584, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6026 - accuracy: 0.9286 - val_loss: 0.6158 - val_accuracy: 0.7381\n",
      "Epoch 35/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5992 - accuracy: 0.9268\n",
      "Epoch 00035: val_loss improved from 0.61584 to 0.61544, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6022 - accuracy: 0.9286 - val_loss: 0.6154 - val_accuracy: 0.7381\n",
      "Epoch 36/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.5988 - accuracy: 0.9189\n",
      "Epoch 00036: val_loss improved from 0.61544 to 0.61530, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.6019 - accuracy: 0.9286 - val_loss: 0.6153 - val_accuracy: 0.7381\n",
      "Epoch 37/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5985 - accuracy: 0.9268\n",
      "Epoch 00037: val_loss improved from 0.61530 to 0.61506, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6014 - accuracy: 0.9286 - val_loss: 0.6151 - val_accuracy: 0.7381\n",
      "Epoch 38/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5981 - accuracy: 0.9231\n",
      "Epoch 00038: val_loss improved from 0.61506 to 0.61463, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6012 - accuracy: 0.9286 - val_loss: 0.6146 - val_accuracy: 0.7381\n",
      "Epoch 39/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.6010 - accuracy: 0.9167\n",
      "Epoch 00039: val_loss improved from 0.61463 to 0.61455, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6008 - accuracy: 0.9286 - val_loss: 0.6145 - val_accuracy: 0.7381\n",
      "Epoch 40/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.6106 - accuracy: 0.9189\n",
      "Epoch 00040: val_loss improved from 0.61455 to 0.61420, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6006 - accuracy: 0.9286 - val_loss: 0.6142 - val_accuracy: 0.7381\n",
      "Epoch 41/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6033 - accuracy: 0.9231\n",
      "Epoch 00041: val_loss improved from 0.61420 to 0.61374, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.6001 - accuracy: 0.9286 - val_loss: 0.6137 - val_accuracy: 0.7619\n",
      "Epoch 42/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.5934 - accuracy: 0.9167\n",
      "Epoch 00042: val_loss improved from 0.61374 to 0.61362, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.5999 - accuracy: 0.9286 - val_loss: 0.6136 - val_accuracy: 0.7619\n",
      "Epoch 43/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.5965 - accuracy: 0.9189\n",
      "Epoch 00043: val_loss improved from 0.61362 to 0.61326, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.5995 - accuracy: 0.9286 - val_loss: 0.6133 - val_accuracy: 0.7619\n",
      "Epoch 44/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5993 - accuracy: 0.9250\n",
      "Epoch 00044: val_loss improved from 0.61326 to 0.61303, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5993 - accuracy: 0.9286 - val_loss: 0.6130 - val_accuracy: 0.7619\n",
      "Epoch 45/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.5892 - accuracy: 0.9189\n",
      "Epoch 00045: val_loss improved from 0.61303 to 0.61274, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5989 - accuracy: 0.9286 - val_loss: 0.6127 - val_accuracy: 0.7619\n",
      "Epoch 46/100\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.5923 - accuracy: 0.9211\n",
      "Epoch 00046: val_loss improved from 0.61274 to 0.61242, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5986 - accuracy: 0.9286 - val_loss: 0.6124 - val_accuracy: 0.7619\n",
      "Epoch 47/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5923 - accuracy: 0.9250\n",
      "Epoch 00047: val_loss improved from 0.61242 to 0.61229, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5983 - accuracy: 0.9286 - val_loss: 0.6123 - val_accuracy: 0.7619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5981 - accuracy: 0.9250\n",
      "Epoch 00048: val_loss improved from 0.61229 to 0.61209, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.5980 - accuracy: 0.9286 - val_loss: 0.6121 - val_accuracy: 0.7619\n",
      "Epoch 49/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5978 - accuracy: 0.9250\n",
      "Epoch 00049: val_loss improved from 0.61209 to 0.61180, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.5978 - accuracy: 0.9286 - val_loss: 0.6118 - val_accuracy: 0.7619\n",
      "Epoch 50/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5945 - accuracy: 0.9268\n",
      "Epoch 00050: val_loss improved from 0.61180 to 0.61178, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.5974 - accuracy: 0.9286 - val_loss: 0.6118 - val_accuracy: 0.7619\n",
      "Epoch 51/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.6042 - accuracy: 0.9167\n",
      "Epoch 00051: val_loss improved from 0.61178 to 0.61123, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5972 - accuracy: 0.9286 - val_loss: 0.6112 - val_accuracy: 0.7619\n",
      "Epoch 52/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5940 - accuracy: 0.9268\n",
      "Epoch 00052: val_loss improved from 0.61123 to 0.61111, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5969 - accuracy: 0.9286 - val_loss: 0.6111 - val_accuracy: 0.8095\n",
      "Epoch 53/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5906 - accuracy: 0.9250\n",
      "Epoch 00053: val_loss improved from 0.61111 to 0.61074, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5966 - accuracy: 0.9286 - val_loss: 0.6107 - val_accuracy: 0.8095\n",
      "Epoch 54/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5964 - accuracy: 0.9250\n",
      "Epoch 00054: val_loss improved from 0.61074 to 0.61072, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5963 - accuracy: 0.9286 - val_loss: 0.6107 - val_accuracy: 0.8095\n",
      "Epoch 55/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5933 - accuracy: 0.9231\n",
      "Epoch 00055: val_loss improved from 0.61072 to 0.61039, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5962 - accuracy: 0.9286 - val_loss: 0.6104 - val_accuracy: 0.8095\n",
      "Epoch 56/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5989 - accuracy: 0.9231\n",
      "Epoch 00056: val_loss improved from 0.61039 to 0.61027, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5958 - accuracy: 0.9286 - val_loss: 0.6103 - val_accuracy: 0.8095\n",
      "Epoch 57/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.6051 - accuracy: 0.9459\n",
      "Epoch 00057: val_loss improved from 0.61027 to 0.61000, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5955 - accuracy: 0.9286 - val_loss: 0.6100 - val_accuracy: 0.8095\n",
      "Epoch 58/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5983 - accuracy: 0.9231\n",
      "Epoch 00058: val_loss improved from 0.61000 to 0.60974, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5952 - accuracy: 0.9286 - val_loss: 0.6097 - val_accuracy: 0.8095\n",
      "Epoch 59/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5950 - accuracy: 0.9250\n",
      "Epoch 00059: val_loss improved from 0.60974 to 0.60954, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.5950 - accuracy: 0.9286 - val_loss: 0.6095 - val_accuracy: 0.8095\n",
      "Epoch 60/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5948 - accuracy: 0.9250\n",
      "Epoch 00060: val_loss improved from 0.60954 to 0.60926, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5947 - accuracy: 0.9286 - val_loss: 0.6093 - val_accuracy: 0.8095\n",
      "Epoch 61/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5912 - accuracy: 0.9487\n",
      "Epoch 00061: val_loss improved from 0.60926 to 0.60898, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5945 - accuracy: 0.9286 - val_loss: 0.6090 - val_accuracy: 0.8095\n",
      "Epoch 62/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5974 - accuracy: 0.9268\n",
      "Epoch 00062: val_loss did not improve from 0.60898\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5944 - accuracy: 0.9286 - val_loss: 0.6090 - val_accuracy: 0.8095\n",
      "Epoch 63/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5911 - accuracy: 0.9268\n",
      "Epoch 00063: val_loss improved from 0.60898 to 0.60844, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5940 - accuracy: 0.9286 - val_loss: 0.6084 - val_accuracy: 0.8095\n",
      "Epoch 64/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5938 - accuracy: 0.9250\n",
      "Epoch 00064: val_loss improved from 0.60844 to 0.60823, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5938 - accuracy: 0.9286 - val_loss: 0.6082 - val_accuracy: 0.8095\n",
      "Epoch 65/100\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.5999 - accuracy: 0.9474\n",
      "Epoch 00065: val_loss did not improve from 0.60823\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5935 - accuracy: 0.9524 - val_loss: 0.6082 - val_accuracy: 0.8095\n",
      "Epoch 66/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5872 - accuracy: 0.9500\n",
      "Epoch 00066: val_loss improved from 0.60823 to 0.60795, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5932 - accuracy: 0.9524 - val_loss: 0.6080 - val_accuracy: 0.8095\n",
      "Epoch 67/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5901 - accuracy: 0.9512\n",
      "Epoch 00067: val_loss improved from 0.60795 to 0.60772, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5930 - accuracy: 0.9524 - val_loss: 0.6077 - val_accuracy: 0.8095\n",
      "Epoch 68/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.6022 - accuracy: 0.9487\n",
      "Epoch 00068: val_loss improved from 0.60772 to 0.60756, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.5927 - accuracy: 0.9524 - val_loss: 0.6076 - val_accuracy: 0.8095\n",
      "Epoch 69/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.5925 - accuracy: 0.9444\n",
      "Epoch 00069: val_loss improved from 0.60756 to 0.60752, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5925 - accuracy: 0.9524 - val_loss: 0.6075 - val_accuracy: 0.8095\n",
      "Epoch 70/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5923 - accuracy: 0.9750\n",
      "Epoch 00070: val_loss improved from 0.60752 to 0.60712, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5923 - accuracy: 0.9762 - val_loss: 0.6071 - val_accuracy: 0.8095\n",
      "Epoch 71/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5920 - accuracy: 0.9750\n",
      "Epoch 00071: val_loss improved from 0.60712 to 0.60699, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5920 - accuracy: 0.9762 - val_loss: 0.6070 - val_accuracy: 0.8095\n",
      "Epoch 72/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5889 - accuracy: 0.9744\n",
      "Epoch 00072: val_loss improved from 0.60699 to 0.60681, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 21ms/sample - loss: 0.5919 - accuracy: 0.9762 - val_loss: 0.6068 - val_accuracy: 0.8095\n",
      "Epoch 73/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.5918 - accuracy: 0.9722\n",
      "Epoch 00073: val_loss did not improve from 0.60681\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5917 - accuracy: 0.9762 - val_loss: 0.6068 - val_accuracy: 0.8095\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5942 - accuracy: 1.0000\n",
      "Epoch 00074: val_loss improved from 0.60681 to 0.60621, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5913 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.8095\n",
      "Epoch 75/100\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.5973 - accuracy: 1.0000\n",
      "Epoch 00075: val_loss improved from 0.60621 to 0.60613, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5911 - accuracy: 1.0000 - val_loss: 0.6061 - val_accuracy: 0.8095\n",
      "Epoch 76/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5879 - accuracy: 1.0000\n",
      "Epoch 00076: val_loss improved from 0.60613 to 0.60553, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5910 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.8095\n",
      "Epoch 77/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.5809 - accuracy: 1.0000\n",
      "Epoch 00077: val_loss did not improve from 0.60553\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5907 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.8095\n",
      "Epoch 78/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.5808 - accuracy: 1.0000\n",
      "Epoch 00078: val_loss did not improve from 0.60553\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5905 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.8095\n",
      "Epoch 79/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5870 - accuracy: 1.0000\n",
      "Epoch 00079: val_loss did not improve from 0.60553\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5904 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.8095\n",
      "Epoch 80/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5870 - accuracy: 1.0000\n",
      "Epoch 00080: val_loss improved from 0.60553 to 0.60511, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5900 - accuracy: 1.0000 - val_loss: 0.6051 - val_accuracy: 0.8095\n",
      "Epoch 81/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.5861 - accuracy: 1.0000\n",
      "Epoch 00081: val_loss improved from 0.60511 to 0.60450, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5898 - accuracy: 1.0000 - val_loss: 0.6045 - val_accuracy: 0.8095\n",
      "Epoch 82/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5926 - accuracy: 1.0000\n",
      "Epoch 00082: val_loss did not improve from 0.60450\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5896 - accuracy: 1.0000 - val_loss: 0.6049 - val_accuracy: 0.8095\n",
      "Epoch 83/100\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.5831 - accuracy: 1.0000\n",
      "Epoch 00083: val_loss did not improve from 0.60450\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5894 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.8095\n",
      "Epoch 84/100\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.5987 - accuracy: 1.0000\n",
      "Epoch 00084: val_loss did not improve from 0.60450\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5892 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.8095\n",
      "Epoch 85/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5860 - accuracy: 1.0000\n",
      "Epoch 00085: val_loss improved from 0.60450 to 0.60444, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5890 - accuracy: 1.0000 - val_loss: 0.6044 - val_accuracy: 0.8095\n",
      "Epoch 86/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5889 - accuracy: 1.0000\n",
      "Epoch 00086: val_loss improved from 0.60444 to 0.60403, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5888 - accuracy: 1.0000 - val_loss: 0.6040 - val_accuracy: 0.8095\n",
      "Epoch 87/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5883 - accuracy: 1.0000\n",
      "Epoch 00087: val_loss improved from 0.60403 to 0.60391, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5886 - accuracy: 1.0000 - val_loss: 0.6039 - val_accuracy: 0.8095\n",
      "Epoch 88/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5853 - accuracy: 1.0000\n",
      "Epoch 00088: val_loss improved from 0.60391 to 0.60369, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5883 - accuracy: 1.0000 - val_loss: 0.6037 - val_accuracy: 0.8095\n",
      "Epoch 89/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5846 - accuracy: 1.0000\n",
      "Epoch 00089: val_loss improved from 0.60369 to 0.60328, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5881 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.8095\n",
      "Epoch 90/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5910 - accuracy: 1.0000\n",
      "Epoch 00090: val_loss did not improve from 0.60328\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5880 - accuracy: 1.0000 - val_loss: 0.6033 - val_accuracy: 0.8095\n",
      "Epoch 91/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5874 - accuracy: 1.0000\n",
      "Epoch 00091: val_loss did not improve from 0.60328\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5877 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.8095\n",
      "Epoch 92/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5845 - accuracy: 1.0000\n",
      "Epoch 00092: val_loss improved from 0.60328 to 0.60308, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5875 - accuracy: 1.0000 - val_loss: 0.6031 - val_accuracy: 0.8095\n",
      "Epoch 93/100\n",
      "36/42 [========================>.....] - ETA: 0s - loss: 0.5807 - accuracy: 1.0000\n",
      "Epoch 00093: val_loss improved from 0.60308 to 0.60279, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5873 - accuracy: 1.0000 - val_loss: 0.6028 - val_accuracy: 0.8095\n",
      "Epoch 94/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5841 - accuracy: 1.0000\n",
      "Epoch 00094: val_loss improved from 0.60279 to 0.60234, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5872 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 0.8095\n",
      "Epoch 95/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5808 - accuracy: 1.0000\n",
      "Epoch 00095: val_loss did not improve from 0.60234\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5869 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 0.8095\n",
      "Epoch 96/100\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.5899 - accuracy: 1.0000\n",
      "Epoch 00096: val_loss did not improve from 0.60234\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5867 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 0.8095\n",
      "Epoch 97/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5835 - accuracy: 1.0000\n",
      "Epoch 00097: val_loss improved from 0.60234 to 0.60220, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5865 - accuracy: 1.0000 - val_loss: 0.6022 - val_accuracy: 0.8095\n",
      "Epoch 98/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5833 - accuracy: 1.0000\n",
      "Epoch 00098: val_loss improved from 0.60220 to 0.60206, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5863 - accuracy: 1.0000 - val_loss: 0.6021 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.5892 - accuracy: 1.0000\n",
      "Epoch 00099: val_loss did not improve from 0.60206\n",
      "42/42 [==============================] - 1s 20ms/sample - loss: 0.5862 - accuracy: 1.0000 - val_loss: 0.6022 - val_accuracy: 0.8095\n",
      "Epoch 100/100\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.5798 - accuracy: 1.0000\n",
      "Epoch 00100: val_loss improved from 0.60206 to 0.60161, saving model to siamese_network.h5\n",
      "42/42 [==============================] - 1s 22ms/sample - loss: 0.5859 - accuracy: 1.0000 - val_loss: 0.6016 - val_accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "\"\"\" train the model \"\"\"\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "siamese.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# siamese.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "siamese.summary()\n",
    "history = siamese.fit([x_train_1, x_train_2],\n",
    "    labels_train,\n",
    "    validation_data=([x_val_1, x_val_2], labels_val),\n",
    "    batch_size=1,\n",
    "    epochs=100,   # 175 for contrastive 100 for cross ent\n",
    "    callbacks = [checkpointer, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "929bb5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "utils.plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c90ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the cross entropy binary loss\n",
    "utils.plt_metric(history=history.history, metric=\"loss\", title=\"Binary Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3064505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296/1296 [==============================] - 5s 4ms/sample - loss: 0.5940 - accuracy: 0.9059\n",
      "test loss, test acc: [0.593962550163269, 0.9058642]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Test the model \"\"\"\n",
    "results = siamese.evaluate([x_test_1, x_test_2], labels_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce353a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17942132, 0.04258977, 0.48759615, ..., 0.02411232, 0.5514468 ,\n",
       "       0.01384273], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = siamese.predict([x_test_1, x_test_2]).squeeze()\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36581777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2678831"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a7a1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False,  True, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred = Y_pred > 0.5\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "934e3302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = labels_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3151112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate on test data\n",
      "Accuracy: 0.9058641975308642\n",
      "Precision: 0.9207792207792207\n",
      "Recall: 0.9058641975308642\n",
      "ROC AUC: 0.9058641975308642\n",
      "F1: 0.9050225501762446\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluate on test data\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2089133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)    \n",
    "# cm_display = ConfusionMatrixDisplay(cm, labels_test).plot()\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a10b0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca300cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
